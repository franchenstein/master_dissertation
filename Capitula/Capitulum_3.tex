\chapter{Algorithm Description}\label{cap:3}

\tikzset{
  treenode/.style = {shape=circle,
                     draw, align=center,
                     top color=white},
  root/.style     = {treenode, font=\ttfamily\normalsize},
  env/.style      = {treenode, font=\ttfamily\normalsize},
  leaf/.style    = {treenode,font=\ttfamily\normalsize, bottom color=red}
}


{\lettrine[loversize=0.25,findent=0.2em,nindent=0em]{I}{n} this chapter, the proposed algorithm to model a system by its sequence \textit{S} is presented. The first section discusses an algorithm to find synchronization words which has lower complexity than the brute force method used by CRISSiS. Later, the PFSA construction algorithm is shown. It is further divided in two parts: the PFSA completion, which will make sure that all states have outgoing edges and the full $\aleph$ algorithm which will create the most compact PFSA for the provided parameters. 

Thus, the proposed algorithm consists of the following three steps: 


\begin{enumerate}
\item[1] Find synchronization words from sequence \textit{S};
\item[2] Apply a termination criterion for the rooted tree with probabilities $\mathcal{S}$ based on \textit{S};
	\begin{enumerate}
	\item Use D-Markov Termination if no synchronization words were found;
	\item Use $\Omega$ if synchronization words were found;
	\end{enumerate}
\item[3] Apply the $\aleph$ algorithm for PFSA construction.
\end{enumerate}

\section{A New Algorithm for Finding Synchronization Words}

Given a sequence \textit{S} of length \textit{N} over an alphabet $\Sigma$ generated by a dynamical system, we introduce in this section an algorithm to find possible synchronization words in \textit{S}. The CRISSiS method uses (\ref{eq:practsynchword}) for an extensive, brute force search.  The proposed algorithm uses data structures in order to speed up the process. This implies using a structured search to realize less statistical tests, which reduces the time complexity of the algorithm, while also finding not only just one synchronization word, but all of them up to a given length \textit{W}.

The proposed algorithm uses a rooted tree with probabilities $\mathcal{S}$ over an alphabet $\Sigma$ to search for synchronization words. At the beginning of the algorithm, all states of $\mathcal{S}$ are considered valid candidates to be synchronization words. A search is performed in $\mathcal{S}$ starting by its root using a statistical test (which compares two state morphs via a test such as $\chi^2$ or Kolmogorov-Smirnov for a given confidence level $\alpha$) to determine whether a state should be expanded. The way the tree is explored guarantees that a state is only tested against other states that have it as a suffix. When a test fails, an expansion algorithm is used to determine how the next states are to be tested. On the other hand, when the test is successful, the keeps its status as a valid candidate.

A rooted tree with probabilities (RTP) $\mathcal{S}$ over $\Sigma = \{0, 1\}$ is presented via an example in Figure \ref{fig:rtp}. It consists of a set of states connected by edges. All states have exactly one predecessor (with the exception of the root state, labeled with the empty string $\epsilon$, which has no predecessors). Leaf states ($0, 10$ and $11$ in the example) have no successors, while the other states have $|\Sigma|$ successors as each element of $\Sigma$ labels its outgoing edges. Those edges are also labeled with the probability of leaving the state with that symbol. Each state is labeled with the string formed from concatenating the symbols in the branches in the path from the root to the current state. The probability of reaching a state is given by multiplying the probabilities labeling the branches in the path from the root state to the current state. For example, consider the leaf state \textit{10}. The path taken from the root state $\epsilon$ is first \textit{1} and then \textit{0}. The probability of reaching this state is $P(1)\times P(0|1)$, that is the probability of leaving the root state with 1 (which is $P(1)$) multiplied by the probability of leaving the state 1 with 0 (that is, $P(0|1$). The edge probabilities of $\mathcal{S}$ are taken from the conditional probabilities of sub-sequences of \textit{S}.

An RTP has its maximum depth \textit{L} ultimately constrained by the length of \textit{S}. If \textit{S} is infinite, $\mathcal{S}$ can also have infinite \textit{L}. In practice, that is not possible and a user defined maximum depth has to be used. It is good to remind that as the chance of sub-sequences occurring gets smaller as their length increases, the statistics of really large sub-sequences might be really poor. This means that using a very large \textit{L} implies that the probabilities of states closer to the leaves tend to be unreliable.

\begin{figure}[h]
\centering
\begin{tikzpicture}
  [
    grow                    = right,
    sibling distance        = 3em,
    level distance          = 6em,
    edge from parent/.style = {draw, -latex},
    every state/.style       = {font=\footnotesize},
    sloped
  ]
  \node [root] {$\epsilon$}
    child { state [env] {1}
      child{ state [leaf] {11}
      	edge from parent state [below] {1/P(1$|$1)}}
      child{ state [leaf] {10}
      	edge from parent state [above] {0/P(0$|$1)}}
      edge from parent state [below] {1/P(1)} }
    child { state [leaf] {0}
      edge from parent state [above] {0/P(0)} };
\end{tikzpicture}
\caption{Example of a rooted tree with probabilities. \label{fig:rtp}}
\end{figure}
 
 Another data structure used in the algorithm is a dictionary (also called a hash table) \citep{thomas2001introduction}. A dictionary $d$ is a mapping between two sets $d: X \rightarrow Y$. The elements from $X$ are called the dictionary's keys. An entry in the dictionary is the element $y \in Y$ associated to the key $x \in X$ and is denoted by $d[x]$, which is also called the \textit{value} of $x$ in $d$. An entry $d[x]$ might be updated and even deleted from $d$.
 
The concept of a \textit{shortest valid suffix} (SVS) also needs to be explained as it is important in one of the algorithm's steps via an auxiliary function called \textit{shortestValidSuffix}. For a given word $\omega \in \Sigma^*$, its SVS is the state from $\mathcal{S}$ labeled with the shortest word that has $\omega$ as a suffix and it is still a valid candidate for synchronization word. The function \textit{shortestValidSuffix} receives the word $\omega = \sigma_1\sigma_2\ldots\sigma_n \in \Sigma^*$ and the tree$\mathcal{S}$ as inputs. A third input is the dictionary \textit{candidacy}, which indicates whether a state is a valid candidate for synchronization word or not. For a given state $x$, the entry \textit{candidacy}$[x]$ has the value \textit{True} if $x$ is a valid candidate and \textit{False} if not. First $\omega$ is reversed, $\omega_{rev} = \sigma_n\sigma_{n-1}\ldots\sigma_1$. Then, the tree $\mathcal{S}$ is traversed according to $\omega_{rev}$, starting at the root $\epsilon$. \textit{candidacy[$\epsilon$]} is checked and if it is true, $\epsilon$ is returned. If not, the state $\delta(\sigma_n, \epsilon)$ is evaluated. At each level $k$ of $\mathcal{S}$, the current state is $c = \delta^*(\sigma_n\ldots\sigma_{n-k},\epsilon)$. Let $c_{rev}$ be the reversed label of the current candidate (i.e. if $c = \tau_1\tau_2\ldots\tau_m$, $c_{rev} = \tau_m\tau_{m-1}\ldots\tau_1$). If \textit{candidacy}[$c_{rev}$] is True, $c_{rev}$ is returned. If not the next iteration is processed until $\omega_{rev}$ is reached, which means that $\omega$ is its own shortest valid suffix if its candidacy is True or that it has no valid suffix if its candidacy is false.
 
 As an example, take the tree $\mathcal{S}$ represented in Figure \ref{fig:treet}, where the filled states indicate that their candidacy status is True while the white states have them as False. If we wish to check which state is the shortest valid suffix for $\omega = 110$ we first take $\omega_{rev} = 011$ and go to the root. As \textit{candidacy}[$\epsilon$] is False, we go to the next iteration, taking $c = \delta(0, \epsilon) = 0$. The candidacy of $c_{rev} = 0$ is checked, which once again is false and takes us to the next iteration. Now $c = \delta^*(01, \epsilon) = 01$, $c_{rev} = 10$ and \textit{candidacy}[$c_{rev}$] = \textit{candidacy}[$10$] = True and the function returns $c_{rev} = 10$, i.e. $10$ is the shortest valid suffix of $110$.

To find the synchronization words, Algorithm \ref{alg:findsynchwords} is used. Its input are the rooted tree with probabilities $\mathcal{S}$, the maximum window size $W$, which is a parameter that determines how deep in the tree the algorithm searches. The algorithm starts by creating the queue $\Gamma$ which contains states from $\mathcal{S}$ that are not fully tested for the synchronization word hypothesis during the current iteration. $\Gamma$ is initialized only with $\epsilon$. A list $\Theta$ is created and initialized empty. It receives the states from $\mathcal{S}$ which currently have passed the statistical test. When a test fails, $\Theta$ is appended to $\Gamma$ and emptied again, as the states in $\Theta$ have to be checked along with other states that might now have them as suffixes. Once all the tests are performed, $\Theta$ is returned as it contains the list of synchronization words by the end of the algorithm.
 
 Three dictionaries are also created. The first one, \textit{candidacy} has already been discussed before. The states from $\mathcal{S}$ are the keys and to each one a boolean value is associated. When a state is still a valid candidate for synchronization word (which means it either had not been tested against its suffixes yet or has passed all the tests up to the current iteration), it has the \textit{True} value associated with it. Once it fails a test and can no longer be considered a valid candidate to be a synchronization word, the associated value becomes \textit{False}. A state for which the \textit{candidacy} value is \textit{True} is called a valid state. At the beginning of the algorithm, all states are valid as they have not been tested yet and their \textit{candidacy} is initialized accordingly.
 
 The second dictionary is called \textit{suffixes} and also has the states from $\mathcal{S}$ as keys. The associated value to each key is a list of states for which the key is the shortest valid suffix, i.e. the key state is the shortest state to have a \textit{True} value for its candidacy and also is a suffix for all the word in the associated list. As $\epsilon$ is the only value to be tested in the beginning of the algorithm, only \textit{suffixes}$[\epsilon]$ is initialized with a list of the states  $\sigma \in \Sigma$ as they all have $\epsilon$ as their shortest valid suffix.
 
 The last dictionary, $V$ stores lists of states associated with their shortest valid suffix as key. states should only be queued into $\Gamma$ if they are their own shortest valid suffix. During a call to Algorithm \ref{alg:expand}, which occurs every time a statistical test fails, if a new state to be added in $\Gamma$ is not its own shortest valid suffix, its shortest valid suffix is used as a key in $V$ and this element is associated with it. If later this shortest valid suffix fails a statistical test, all elements associated with it in $V$ have to be checked again to see if now they are their own shortest valid suffixes.
 
When two states $p, q \in \mathcal{S}$ are compared (with the notation $\mathcal{V}(p) = \mathcal{V}(q)$ it means that their morphs are compared via an appropriate statistical test (such as the $\chi^2$ test or Kolmogorov-Smirnov test) with a predetermined confidence level $\alpha$.
 
  
\begin{figure}[h]
\centering
\tikzstyle{level 1}=[level distance=3cm, sibling distance=4.5cm]
\tikzstyle{level 2}=[level distance=4cm, sibling distance=2.5cm]
\tikzstyle{level 3}=[level distance=4cm, sibling distance=1cm]
\begin{tikzpicture}
	[
    grow = right,
    edge from parent/.style = {draw, -latex},
    every state/.style       = {font=\footnotesize},
    sloped    
    ]
  \node [root] {$\epsilon$}
    child { state [env] {1}
      child{ state [env] {11}
      	child{ state [leaf] {111}
        	edge from parent state [below] {1/$P(1|11)$}}
      	child{ state [leaf] {110}
        	edge from parent state [above] {0/$P(0|11)$}}
      	edge from parent state [below] {1/P(1$|$1)}}
      child{ state [leaf] {10}
      	child{ state [leaf] {101}
        	edge from parent state [below] {1/$P(1|10)$}}
      	child{ state [leaf] {100}
        	edge from parent state [above] {0/$P(0|10)$}}
      	edge from parent state [above] {0/P(0$|$1)}}
      edge from parent state [below] {1/P(1)} }
    child { state [env] {0}
      child{ state [env] {01}
       	child{ state [leaf] {011}
         	edge from parent state [below] {1/$P(1|01)$}}
       	child{ state [leaf] {010}
         	edge from parent state [above] {0/$P(0|01)$}}
      	edge from parent state [below] {1/P(1$|$0)}}
      child{ state [leaf] {00}
       	child{ state [leaf] {001}
         	edge from parent state [below] {1/$P(1|00)$}}
       	child{ state [leaf] {000}
         	edge from parent state [above] {0/$P(0|00)$}}
      	edge from parent state [above] {0/P(0$|$0)}}
      edge from parent state [above] {0/P(0)} };
\end{tikzpicture}
\caption{Example of binary $\mathcal{S}$ \label{fig:treet}}
\end{figure}

The main loop then begins. At the start of each iteration, the variable $c$ receives the first element of $\Gamma$ via dequeueing (as $\Gamma$ is a queue, the first element to be inserted into it is the first to be removed). If the label of $c$ (denoted by $c$.label) is longer than $W$, the algorithm stops and returns the list $\Theta$. If it is not, a flag $p$ is set to True and it will be used to store the result of the statistical tests. If \textit{suffixes}[$c$] is empty, $p$ will stay True. On the other hand, if there are states for which $c$ is a suffix, \textit{suffixes}[$c$] will be iterated. Each element of \textit{suffixes}[$c$] goes through the statistical test with $c$. This is done to check if the states that have $c$ as suffix have morphs statistically equal to the morph of $c$. For each of these tests, $p$ is updated. If all tests are true, $p$ is True by the end of it and $c$ gets to keep its status as a valid candidate for synchronization word and it is appended at $\Theta$ as it currently is a valid candidate synchronization word and it passed in all its tests. If one of the tests fails, $p$ is set to False and no more tests need to be done for $c$. The candidacy of $c$ will be set to False, the list $\Gamma$ and the dictionaries will be expanded according to Algorithm \ref{alg:expand} (which will be explained later) and for each element $\theta \in \Theta$ will need to be tested again for the new elements appended to \textit{suffixes}[$\theta$] after the expansion. This means that each element of $\Theta$ is concatenated at the end of $\Gamma$ and then it will be set to the empty set again. This procedure is repeated until either the queue $\Gamma$ is empty or if all the elements in $\Gamma$ have labels longer than $W$. It will return $\Theta$, with all the elements that passed in all their statistical tests, meaning that they are synchronization words according to (\ref{eq:practsynchword}). 

\begin{algorithm} 
  \caption{findSynchWords($W, \mathcal{S}$)\label{alg:findsynchwords}}
    \begin{algorithmic}[1]
      \Procedure{Initialization}{}
      	\State $\Gamma \gets \{\epsilon \in \mathcal{S}\}$ 
        \State \textit{suffixes}$[\epsilon ] \gets \{\delta (\sigma , \epsilon) \forall \sigma \in \Sigma \}$
        \State $V \gets$ empty dictionary
        \For{$s \in \mathcal{S}$}
        	\State \textit{candidacy}$[s] = $ True
        \EndFor
        \State $\Theta \gets \emptyset$ 
      \EndProcedure	
      \Procedure{MainLoop}{}
      	\While{$\Gamma \neq \emptyset$}
        	\State $\textit{c} \leftarrow$ dequeue$(\Gamma)$
        	\If {length$(c.$label$) < W$}
        		\State $p \leftarrow$ True
        		\If {$\Lambda \neq \emptyset$}
        			\For{\textbf{every} $\lambda \in$ \textit{suffixes}$[c]$}
        				\State $p \leftarrow$ \textit{statisticalTest}($\mathcal{V}(c), \mathcal{V}(\lambda), \alpha)$
        				\If {$p =$ False}
        					\State candidacy$[c] \gets$ False
        					\State expand($c, V, \mathcal{S}, \Gamma,$ candidacy, suffixes$)$
        					\For{\textbf{every} $\theta \in \Theta$}
        						\State $\Gamma$.queue$(\theta)$
        					\EndFor
        					\State $\Theta \leftarrow \emptyset$
        					\State \textbf{break}
        				\EndIf
        			\EndFor
        		\EndIf
        		\If {$p =$ True}
        			\State $\Theta$.\textit{append}($c$)
        		\EndIf
        	\EndIf
      	\EndWhile
      	\State \textbf{return} $\Theta$
      \EndProcedure
    \end{algorithmic}
  \end{algorithm}
  
Algorithm \ref{alg:expand} updates $\Gamma$ and the dictionaries \textit{suffixes} and $V$ after a statistical test fails. First, a list $\Psi$ with all the descendants of the state $c$ is created. This list holds the elements that need to be checked if they can be queued into $\Gamma$. They will be queued if they are their own SVS. If there is a list associated to $c$ in $V$, all its elements are appended to $\Psi$. Those are the elements that instead of being their own SVS, had $c$ as the shortest valid suffix. The entry $V[c]$ is then deleted as it no longer has a use.

The next step is to iterate for each element $d$ in $\Psi$ and check if they are their own SVS using the \textit{shortestValidSuffix} function and comparing if the returned state is $d$. If they are not, this means that there are shorter words that need to be checked before them. In this case, the entry $V[\zeta]$ is created, where $\zeta$ is the SVS of $d$, and $d$ is stored in this list. Once this $\zeta$ is tested in Algorithm \ref{alg:findsynchwords} and if it fails its statistical test, this $d$ will be checked again to see if it is its SVS.

On the other hand, if $\zeta = d$, this element is then added to the end of the queue $\Gamma$ and it will be later dequeued and tested.  The last step is to update the suffix dictionary so there are new elements to be compared with their suffixes. The list ofall the descendants of $\zeta$ is iterated. The shortest valid suffix \textit{short} of each of its elements $t$ is found and used as an entry of \textit{suffixes}, such that \textit{suffixes}[short] appends $t$.
  
  \begin{algorithm}
  \caption{expand($c, V, \mathcal{S},\Gamma,$ candidacy, suffixes)\label{alg:expand}}
    \begin{algorithmic}[1]
      \Procedure{Expand $\Gamma$}{}
      	\State $\Psi \gets \{\delta(\sigma,c),\forall \sigma \in \Sigma\}$
      	\If {$c$ is a key of $V$}
      		\State $\Psi \gets \Psi \cup V[c]$
      		\State delete $V[c]$
      	\EndIf
      	\For{\textbf{every} $d \in \Psi$}
      		\State $\zeta \gets $ \textit{shortestValidSuffix}$(\mathcal{S}, d,$ \textit{candidacy}$)$
      		\If{$\zeta = d$}
      			\State $\Gamma$.queue($\zeta$)
      			\For{$t \in\{\delta(\sigma, \zeta) \forall \sigma \in \Sigma\}$}
      				\State short $\gets $ \textit{shortestValidSuffix}$(\mathcal{S}, t,$ candidacy$)$
      				\State \textit{suffixes}$[$short$]$.\textit{append}($t$)
      			\EndFor
      		\Else
      			\If{$V[\zeta] = \emptyset$}
      				\State $V[\zeta] \gets \{d\}$
      			\Else
      				\State $V[\zeta]$.\textit{append}($d$)
      			\EndIf
      		\EndIf
      	\EndFor
      \EndProcedure
    \end{algorithmic}
  \end{algorithm}

\subsection{An Example}

To illustrate how the algorithm works, the Tri-Shift as it can be compared to CRISSiS in Section \ref{sec:crissis}. All statistical tests in this section use the $\chi^2$ test with $\alpha = 0.95$. The initial RTP for $W = 3$ and $L = 4$ is shown in Figure \ref{fig:trishifttree0}. The queue $\Gamma$ is initialized with the root of $\mathcal{S}$. The dictionary \textit{suffixes} is initialized with  \textit{suffixes}[$\epsilon$] = \{0, 1\}. $V$ is initialized as an empty dictionary, $\Theta$ is initialized as an empty list and all the states start with their candidacy set to True.

As $\Gamma$ is not empty, it is dequeued and $c = \epsilon$, which has a label length of zero and is shorter than $W = 3$. It then proceeds to iterate through \textit{suffixes}[$c$] = \textit{suffixes}[$\epsilon$] = $\{0, 1\}$ and $p$ is set to true. It first compares $\mathcal{V}(\epsilon) = \mathcal{V}(0)$. As the morphs are [0.6276, 0.3274] and [0.5615, 0.4385], the test fails, which means $\epsilon$ candidacy is set to False and the expansion algorithm is called. 

The list $\Psi$ is initialized with the direct descendants of $c = \epsilon$, that is $\Psi = \{0, 1\}$. $V[\epsilon]$ is empty and can be disregarded. It is easy to check that all elements in $\Psi$ are their own shortest valid suffixes after $\epsilon$ candidacy becomes false (seen in Figure \ref{fig:trishifttree1}). This means both of them are queued into $\Gamma$, so that $\Gamma = \{0, 1\}$. For both 0 and 1, they are their direct descendants' shortest valid suffixes, which means that suffixes[0] = \{00, 10\} and suffixes[1] = \{01, 11\}. The expansion algorithm returns to the synchronization algorithm. The list $\Theta$ is appended to the end of $\Gamma$, but as it is currently empty it does not change $\Gamma$. This ends the first iteration. 

\begin{figure}[h]
\centering
\tikzstyle{level 1}=[level distance=2.5cm, sibling distance=11.5cm]
\tikzstyle{level 2}=[level distance=2.5cm, sibling distance=5.5cm]
\tikzstyle{level 3}=[level distance=3.5cm, sibling distance=3cm]
\tikzstyle{level 4}=[level distance=4.5cm, sibling distance=1.25cm]
\begin{tikzpicture}
	[
    grow = right,
    edge from parent/.style = {draw, -latex},
    every state/.style       = {font=\footnotesize},
    sloped    
    ]
  \node [leaf] {$\epsilon$}
    child { state [leaf] {1}
      child{ state [leaf] {11}
      	child{ state [leaf] {111}
      		child{ state [leaf] {1111}
      			edge from parent state [below] {1/0.2606}}
      		child{ state [leaf] {1110}
      			edge from parent state [above] {0/0.7394}}
        	edge from parent state [below] {1/0.3744}}
      	child{ state [leaf] {110}
      		child{ state [leaf] {1101}
      			edge from parent state [below] {1/0.4364}}
      		child{ state [leaf] {1100}
      			edge from parent state [above] {0/0.5636}}
        	edge from parent state [above] {0/0.6256}}
      	edge from parent state [below] {1/0.2610}}
      child{ state [leaf] {10}
      	child{ state [leaf] {101}
      		child{ state [leaf] {1011}
      			edge from parent state [below] {1/0.7417}}
      		child{ state [leaf] {1010}
      			edge from parent state [above] {0/0.2583}}
        	edge from parent state [below] {1/0.3597}}
      	child{ state [leaf] {100}
      		child{ state [leaf] {1001}
      			edge from parent state [below] {1/0.5000}}
      		child{ state [leaf] {1000}
      			edge from parent state [above] {0/0.5000}}
        	edge from parent state [above] {0/0.6403}}
      	edge from parent state [above] {0/0.7390}}
      edge from parent state [below] {1/0.3724} }
    child { state [leaf] {0}
      child{ state [leaf] {01}
       	child{ state [leaf] {011}
      		child{ state [leaf] {0111}
      			edge from parent state [below] {1/0.4425}}
      		child{ state [leaf] {0110}
      			edge from parent state [above] {0/0.5575}}
         	edge from parent state [below] {1/0.2210}}
       	child{ state [leaf] {010}
      		child{ state [leaf] {0101}
      			edge from parent state [below] {1/0.3380}}
      		child{ state [leaf] {0100}
      			edge from parent state [above] {0/0.6620}}
         	edge from parent state [above] {0/0.7790}}
      	edge from parent state [below] {1/0.4385}}
      child{ state [leaf] {00}
       	child{ state [leaf] {001}
      		child{ state [leaf] {0011}
      			edge from parent state [below] {1/0.2000}}
      		child{ state [leaf] {0010}
      			edge from parent state [above] {0/0.8000}}
         	edge from parent state [below] {1/0.5000}}
       	child{ state [leaf] {000}
      		child{ state [leaf] {0001}
      			edge from parent state [below] {1/0.5000}}
      		child{ state [leaf] {0000}
      			edge from parent state [above] {0/0.5000}}
         	edge from parent state [above] {0/0.5000}}
      	edge from parent state [above] {0/0.5615}}
      edge from parent state [above] {0/0.6276} };
\end{tikzpicture}
\caption{Input Rooted Tree with Probabilities $\mathcal{S}$ for the Tri-Shift Example. \label{fig:trishifttree0}}
\end{figure}

At the beginning of the next iteration, $\Gamma = \{0, 1\}$ and when it is dequeued, $c = 0$, whose label is still shorter than $W$. The list \textit{suffixes}[$0$] $= \{00, 10\}$ has each of its elements tested. First to be tested is $00$ and $\mathcal{V}(0) = \mathcal{V}(00)$ returns False as $\mathcal{V}(0) = [0.5615, 0.4385]$ diverges significantly from $\mathcal{V}(00) = [0.5, 0.5]$. This means that \textit{candidacy}[$0$] is set to False and the expansion algorithm is called.

For $c = 0$, the expansion algorithm has $\Psi = \{00, 01\}$ and $0$ is not among the keys of $V$, so no other elements are appended to $\Psi$. First, the SVS is checked for $00$ and by examining the tree, it is observed that it is its own shortest valid suffix. This means that $00$ is queued into $\Gamma$. Its children, $000$ and $001$ have $00$ and $1$ as shortest valid suffixes, so the \textit{suffixes} dictionary is updated to \textit{suffixes}[$000$] = $\{000\}$ and suffixes[$1$] = $\{01, 11, 001\}$. Next, the shortest valid suffix of $01$ is shown to be $1$, which means it is not its own shortest valid suffix. This means it has to be appended to $V[1]$, which makes it $V[1] = \{01\}$. The empty list $\Theta$ is once again appended to $\Gamma$ and re-emptied. 

In the beginning of the next iteration, we have $\Gamma = \{1, 000\}$, $V[1] = \{01\}$, $\Theta = \emptyset$, suffixes[$1$] = $\{01, 11, 001\}$ and suffixes[$00$] = $\{000\}$. $\Gamma$ is dequeued and $c = 1$, \textit{suffixes}[$1$] = $\{01, 11, 001\}$ is iterated through. First, $\mathcal{V}(1) = \mathcal{V}(01)$ is checked to be false ($[0.779, 0.221]$ against $[0.739, 0.261]$) making \textit{candidacy}[$1$] = False and the call to the expansion algorithm.

In the expansion algorithm, $\Psi = \{10, 11\}$ and it is appended of $01$ because $V[1] = \{01\}$, making $\Psi = \{10, 11, 01\}$. Now that both \textit{candidacy}[$0$] = \textit{candidacy}[$1$] = False, all of them are their own shortest valid suffixes and they are their children states' shortest valid suffixes. Thus, $\Gamma = \{00, 01, 10, 11\}$ and \textit{suffixes}[$00$] = $\{000, 100\}$, \textit{suffixes}[$01$] = $\{001, 101\}$, \textit{suffixes}[$10$] = $\{010, 110\}$ and \textit{suffixes}[$11$] = $\{011, 111\}$. Once again $\Theta$ is appended in $\Gamma$ and emptied.

The fourth iteration has $c = 00$ and \textit{suffixes}[$c$]$ = \{000, 100\}$. All the states in \textit{suffixes}[$c$] have the same morph as $c$, so it passes all its tests, keeps its candidacy as True and it is added to $\Theta$.

At the beginning of the next iteration, $\Gamma = \{01, 10, 11\}$, $\Theta = \{00\}$, \textit{suffixes}[$01$] = $\{001, 101\}$, \textit{suffixes}[$10$] = $\{010, 110\}$ and \textit{suffixes}[$11$] = $\{011, 111\}$. After dequeueing, $c = 01$ and \textit{suffixes}[$c$]$ = \{001, 101\}$. The test $\mathcal{V}(01) = \mathcal{V}(001)$ fails ([0.779, 0.221] against [0.8, 0.2]). During the expansion, $\Psi = \{010, 011\}$ and $V[01] = \emptyset$. 010 is its own shortest valid suffix, but 011 is not (its shortest valid suffix is 11). This means $V[11] = \{011\}$ and $\Gamma$ appends 010. The children of 010 are 0100 and 0101 and will be added to \textit{suffixes}[00] and \textit{suffixes}[101]. After the expansion, $\Theta = \{00\}$ is appended to $\Gamma$.

In the sixth iteration, $\Gamma = \{10, 11, 010, 00\}$, $V[11] = \{011\}$, \textit{suffixes}[$10$] = $\{010, 110\}$, \textit{suffixes}[$11$] = $\{011, 111\}$,  \textit{suffixes}[$010$] = $\emptyset$ and  \textit{suffixes}[$00$] = $\{000, 100, 0100\}$. $c = 10$, \textit{suffixes}[$c$]$ = \{010, 110\}$ and $\mathcal{V}(10) = \mathcal{V}(010)$ fails ([0.6403, 0.3597] against [0.662, 0.338]). The expansion has $\Psi = \{100, 101\}$. 100 has 00 as shortest valid suffix, therefore it is not appended to $\Gamma$ and $V[00] = \{100\}$. 101 is its own shortest valid suffix so it is queued into $\Gamma$ and its children are 1010 and 1011 which are added to \textit{suffixes}[010] and \textit{suffixes}[11].

The following iteration has $\Gamma = \{11, 010, 00, 101\}$, $V[11] = \{011\}$, $V[00] = \{100\}$, \textit{suffixes}[$11$] = $\{011, 111, 1011\}$,  \textit{suffixes}[$010$] = $\{1010\}$, \textit{suffixes}[$00$] = $\{000, 100, 0100\}$ and \textit{suffixes}[$101$] = $\{0101\}$. $c = 11$ and \textit{suffixes}[$c$]$ = \{011, 111, 1011\}$. The test $\mathcal{V}(11) = \mathcal{V}(011)$ fails ([0.6256, 0.3744] against [0.5575, 0.4425]). In the expansion for $c = 11$, $\Psi = \{110, 111, 011\}$ (because $V[11] = \{011\}$).  All of them are their own shortest valid suffixes, so they are appended to $\Gamma$ and suffixes is updated with \textit{suffixes}[00] receiving 1100; \textit{suffixes}[101] receives 1101; \textit{suffixes}[110], 1110 and 0110; \textit{suffixes}[111], 1111 and 0111.

In the eight iteration, $\Gamma = \{010, 00, 101, 110, 111, 011\}$, $V[00] = \{100\}$, \textit{suffixes}[$010$] = $\{1010\}$, \textit{suffixes}[$00$] = $\{000, 100, 0100, 1100\}$, \textit{suffixes}[$101$] = $\{0101, 1101\}$, \textit{suffixes}[$110$] = $\{1110, 0110\}$, \textit{suffixes}[$111$] = $\{1111, 0111\}$ and \textit{suffixes}[$011$] = $\{1011\}$. $c = 010$ which is now equal in length to $W = 3$, which means it is no longer tested.

In the ninth iteration, $c = 00$ and $\Lambda = \{000, 100, 0100, 1100\}$. All of these states have morphs close to [0.5, 0.5] and they pass in all statistical test. This keeps 00 candidacy as True and it is once again added to $\Theta$. The rest of the elements in $\Gamma = \{101, 110, 111, 011\}$ have labels equal to than $W$ so they are all skipped and the algorithm returns $\Theta = \{00\}$. This result is the same as the one found by CRISSiS. Although this Algorithm seems more contrived, less statistical tests were performed and the search was more thorough than CRISSiS.

\begin{figure}[h]
\centering
\tikzstyle{level 1}=[level distance=2.5cm, sibling distance=11.5cm]
\tikzstyle{level 2}=[level distance=2.5cm, sibling distance=5.5cm]
\tikzstyle{level 3}=[level distance=3.5cm, sibling distance=3cm]
\tikzstyle{level 4}=[level distance=4.5cm, sibling distance=1.25cm]
\begin{tikzpicture}
	[
    grow = right,
    edge from parent/.style = {draw, -latex},
    every state/.style       = {font=\footnotesize},
    sloped    
    ]
  \node [env] {$\epsilon$}
    child { state [leaf] {1}
      child{ state [leaf] {11}
      	child{ state [leaf] {111}
      		child{ state [leaf] {1111}
      			edge from parent state [below] {1/0.2606}}
      		child{ state [leaf] {1110}
      			edge from parent state [above] {0/0.7394}}
        	edge from parent state [below] {1/0.3744}}
      	child{ state [leaf] {110}
      		child{ state [leaf] {1101}
      			edge from parent state [below] {1/0.4364}}
      		child{ state [leaf] {1100}
      			edge from parent state [above] {0/0.5636}}
        	edge from parent state [above] {0/0.6256}}
      	edge from parent state [below] {1/0.2610}}
      child{ state [leaf] {10}
      	child{ state [leaf] {101}
      		child{ state [leaf] {1011}
      			edge from parent state [below] {1/0.7417}}
      		child{ state [leaf] {1010}
      			edge from parent state [above] {0/0.2583}}
        	edge from parent state [below] {1/0.3597}}
      	child{ state [leaf] {100}
      		child{ state [leaf] {1001}
      			edge from parent state [below] {1/0.5000}}
      		child{ state [leaf] {1000}
      			edge from parent state [above] {0/0.5000}}
        	edge from parent state [above] {0/0.6403}}
      	edge from parent state [above] {0/0.7390}}
      edge from parent state [below] {1/0.3724} }
    child { state [leaf] {0}
      child{ state [leaf] {01}
       	child{ state [leaf] {011}
      		child{ state [leaf] {0111}
      			edge from parent state [below] {1/0.4425}}
      		child{ state [leaf] {0110}
      			edge from parent state [above] {0/0.5575}}
         	edge from parent state [below] {1/0.2210}}
       	child{ state [leaf] {010}
      		child{ state [leaf] {0101}
      			edge from parent state [below] {1/0.3380}}
      		child{ state [leaf] {0100}
      			edge from parent state [above] {0/0.6620}}
         	edge from parent state [above] {0/0.7790}}
      	edge from parent state [below] {1/0.4385}}
      child{ state [leaf] {00}
       	child{ state [leaf] {001}
      		child{ state [leaf] {0011}
      			edge from parent state [below] {1/0.2000}}
      		child{ state [leaf] {0010}
      			edge from parent state [above] {0/0.8000}}
         	edge from parent state [below] {1/0.5000}}
       	child{ state [leaf] {000}
      		child{ state [leaf] {0001}
      			edge from parent state [below] {1/0.5000}}
      		child{ state [leaf] {0000}
      			edge from parent state [above] {0/0.5000}}
         	edge from parent state [above] {0/0.5000}}
      	edge from parent state [above] {0/0.5615}}
      edge from parent state [above] {0/0.6276} };
\end{tikzpicture}
\caption{Rooted Tree with Probabilities $\mathcal{S}$ for the Tri-Shift Example after the first iteration. \label{fig:trishifttree1}}
\end{figure}

\begin{figure}[h]
\centering
\tikzstyle{level 1}=[level distance=2.5cm, sibling distance=11.5cm]
\tikzstyle{level 2}=[level distance=2.5cm, sibling distance=5.5cm]
\tikzstyle{level 3}=[level distance=3.5cm, sibling distance=3cm]
\tikzstyle{level 4}=[level distance=4.5cm, sibling distance=1.25cm]
\begin{tikzpicture}
	[
    grow = right,
    edge from parent/.style = {draw, -latex},
    every state/.style       = {font=\footnotesize},
    sloped    
    ]
  \node [env] {$\epsilon$}
    child { state [leaf] {1}
      child{ state [leaf] {11}
      	child{ state [leaf] {111}
      		child{ state [leaf] {1111}
      			edge from parent state [below] {1/0.2606}}
      		child{ state [leaf] {1110}
      			edge from parent state [above] {0/0.7394}}
        	edge from parent state [below] {1/0.3744}}
      	child{ state [leaf] {110}
      		child{ state [leaf] {1101}
      			edge from parent state [below] {1/0.4364}}
      		child{ state [leaf] {1100}
      			edge from parent state [above] {0/0.5636}}
        	edge from parent state [above] {0/0.6256}}
      	edge from parent state [below] {1/0.2610}}
      child{ state [leaf] {10}
      	child{ state [leaf] {101}
      		child{ state [leaf] {1011}
      			edge from parent state [below] {1/0.7417}}
      		child{ state [leaf] {1010}
      			edge from parent state [above] {0/0.2583}}
        	edge from parent state [below] {1/0.3597}}
      	child{ state [leaf] {100}
      		child{ state [leaf] {1001}
      			edge from parent state [below] {1/0.5000}}
      		child{ state [leaf] {1000}
      			edge from parent state [above] {0/0.5000}}
        	edge from parent state [above] {0/0.6403}}
      	edge from parent state [above] {0/0.7390}}
      edge from parent state [below] {1/0.3724} }
    child { state [env] {0}
      child{ state [leaf] {01}
       	child{ state [leaf] {011}
      		child{ state [leaf] {0111}
      			edge from parent state [below] {1/0.4425}}
      		child{ state [leaf] {0110}
      			edge from parent state [above] {0/0.5575}}
         	edge from parent state [below] {1/0.2210}}
       	child{ state [leaf] {010}
      		child{ state [leaf] {0101}
      			edge from parent state [below] {1/0.3380}}
      		child{ state [leaf] {0100}
      			edge from parent state [above] {0/0.6620}}
         	edge from parent state [above] {0/0.7790}}
      	edge from parent state [below] {1/0.4385}}
      child{ state [leaf] {00}
       	child{ state [leaf] {001}
      		child{ state [leaf] {0011}
      			edge from parent state [below] {1/0.2000}}
      		child{ state [leaf] {0010}
      			edge from parent state [above] {0/0.8000}}
         	edge from parent state [below] {1/0.5000}}
       	child{ state [leaf] {000}
      		child{ state [leaf] {0001}
      			edge from parent state [below] {1/0.5000}}
      		child{ state [leaf] {0000}
      			edge from parent state [above] {0/0.5000}}
         	edge from parent state [above] {0/0.5000}}
      	edge from parent state [above] {0/0.5615}}
      edge from parent state [above] {0/0.6276} };
\end{tikzpicture}
\caption{Rooted Tree with Probabilities $\mathcal{S}$ for the Tri-Shift Example after the second iteration. \label{fig:trishifttree2}}
\end{figure}

\begin{figure}[h]
\centering
\tikzstyle{level 1}=[level distance=2.5cm, sibling distance=11.5cm]
\tikzstyle{level 2}=[level distance=2.5cm, sibling distance=5.5cm]
\tikzstyle{level 3}=[level distance=3.5cm, sibling distance=3cm]
\tikzstyle{level 4}=[level distance=4.5cm, sibling distance=1.25cm]
\begin{tikzpicture}
	[
    grow = right,
    edge from parent/.style = {draw, -latex},
    every state/.style       = {font=\footnotesize},
    sloped    
    ]
  \node [env] {$\epsilon$}
    child { state [env] {1}
      child{ state [leaf] {11}
      	child{ state [leaf] {111}
      		child{ state [leaf] {1111}
      			edge from parent state [below] {1/0.2606}}
      		child{ state [leaf] {1110}
      			edge from parent state [above] {0/0.7394}}
        	edge from parent state [below] {1/0.3744}}
      	child{ state [leaf] {110}
      		child{ state [leaf] {1101}
      			edge from parent state [below] {1/0.4364}}
      		child{ state [leaf] {1100}
      			edge from parent state [above] {0/0.5636}}
        	edge from parent state [above] {0/0.6256}}
      	edge from parent state [below] {1/0.2610}}
      child{ state [leaf] {10}
      	child{ state [leaf] {101}
      		child{ state [leaf] {1011}
      			edge from parent state [below] {1/0.7417}}
      		child{ state [leaf] {1010}
      			edge from parent state [above] {0/0.2583}}
        	edge from parent state [below] {1/0.3597}}
      	child{ state [leaf] {100}
      		child{ state [leaf] {1001}
      			edge from parent state [below] {1/0.5000}}
      		child{ state [leaf] {1000}
      			edge from parent state [above] {0/0.5000}}
        	edge from parent state [above] {0/0.6403}}
      	edge from parent state [above] {0/0.7390}}
      edge from parent state [below] {1/0.3724} }
    child { state [env] {0}
      child{ state [leaf] {01}
       	child{ state [leaf] {011}
      		child{ state [leaf] {0111}
      			edge from parent state [below] {1/0.4425}}
      		child{ state [leaf] {0110}
      			edge from parent state [above] {0/0.5575}}
         	edge from parent state [below] {1/0.2210}}
       	child{ state [leaf] {010}
      		child{ state [leaf] {0101}
      			edge from parent state [below] {1/0.3380}}
      		child{ state [leaf] {0100}
      			edge from parent state [above] {0/0.6620}}
         	edge from parent state [above] {0/0.7790}}
      	edge from parent state [below] {1/0.4385}}
      child{ state [leaf] {00}
       	child{ state [leaf] {001}
      		child{ state [leaf] {0011}
      			edge from parent state [below] {1/0.2000}}
      		child{ state [leaf] {0010}
      			edge from parent state [above] {0/0.8000}}
         	edge from parent state [below] {1/0.5000}}
       	child{ state [leaf] {000}
      		child{ state [leaf] {0001}
      			edge from parent state [below] {1/0.5000}}
      		child{ state [leaf] {0000}
      			edge from parent state [above] {0/0.5000}}
         	edge from parent state [above] {0/0.5000}}
      	edge from parent state [above] {0/0.5615}}
      edge from parent state [above] {0/0.6276} };
\end{tikzpicture}
\caption{Rooted Tree with Probabilities $\mathcal{S}$ for the Tri-Shift Example after the third and fourth iterations. \label{fig:trishifttree34}}
\end{figure}

\begin{figure}[h]
\centering
\tikzstyle{level 1}=[level distance=2.5cm, sibling distance=11.5cm]
\tikzstyle{level 2}=[level distance=2.5cm, sibling distance=5.5cm]
\tikzstyle{level 3}=[level distance=3.5cm, sibling distance=3cm]
\tikzstyle{level 4}=[level distance=4.5cm, sibling distance=1.25cm]
\begin{tikzpicture}
	[
    grow = right,
    edge from parent/.style = {draw, -latex},
    every state/.style       = {font=\footnotesize},
    sloped    
    ]
  \node [env] {$\epsilon$}
    child { state [env] {1}
      child{ state [leaf] {11}
      	child{ state [leaf] {111}
      		child{ state [leaf] {1111}
      			edge from parent state [below] {1/0.2606}}
      		child{ state [leaf] {1110}
      			edge from parent state [above] {0/0.7394}}
        	edge from parent state [below] {1/0.3744}}
      	child{ state [leaf] {110}
      		child{ state [leaf] {1101}
      			edge from parent state [below] {1/0.4364}}
      		child{ state [leaf] {1100}
      			edge from parent state [above] {0/0.5636}}
        	edge from parent state [above] {0/0.6256}}
      	edge from parent state [below] {1/0.2610}}
      child{ state [leaf] {10}
      	child{ state [leaf] {101}
      		child{ state [leaf] {1011}
      			edge from parent state [below] {1/0.7417}}
      		child{ state [leaf] {1010}
      			edge from parent state [above] {0/0.2583}}
        	edge from parent state [below] {1/0.3597}}
      	child{ state [leaf] {100}
      		child{ state [leaf] {1001}
      			edge from parent state [below] {1/0.5000}}
      		child{ state [leaf] {1000}
      			edge from parent state [above] {0/0.5000}}
        	edge from parent state [above] {0/0.6403}}
      	edge from parent state [above] {0/0.7390}}
      edge from parent state [below] {1/0.3724} }
    child { state [env] {0}
      child{ state [env] {01}
       	child{ state [leaf] {011}
      		child{ state [leaf] {0111}
      			edge from parent state [below] {1/0.4425}}
      		child{ state [leaf] {0110}
      			edge from parent state [above] {0/0.5575}}
         	edge from parent state [below] {1/0.2210}}
       	child{ state [leaf] {010}
      		child{ state [leaf] {0101}
      			edge from parent state [below] {1/0.3380}}
      		child{ state [leaf] {0100}
      			edge from parent state [above] {0/0.6620}}
         	edge from parent state [above] {0/0.7790}}
      	edge from parent state [below] {1/0.4385}}
      child{ state [leaf] {00}
       	child{ state [leaf] {001}
      		child{ state [leaf] {0011}
      			edge from parent state [below] {1/0.2000}}
      		child{ state [leaf] {0010}
      			edge from parent state [above] {0/0.8000}}
         	edge from parent state [below] {1/0.5000}}
       	child{ state [leaf] {000}
      		child{ state [leaf] {0001}
      			edge from parent state [below] {1/0.5000}}
      		child{ state [leaf] {0000}
      			edge from parent state [above] {0/0.5000}}
         	edge from parent state [above] {0/0.5000}}
      	edge from parent state [above] {0/0.5615}}
      edge from parent state [above] {0/0.6276} };
\end{tikzpicture}
\caption{Rooted Tree with Probabilities $\mathcal{S}$ for the Tri-Shift Example after the fifth iteration. \label{fig:trishifttree5}}
\end{figure}
\begin{figure}[h]
\centering
\tikzstyle{level 1}=[level distance=2.5cm, sibling distance=11.5cm]
\tikzstyle{level 2}=[level distance=2.5cm, sibling distance=5.5cm]
\tikzstyle{level 3}=[level distance=3.5cm, sibling distance=3cm]
\tikzstyle{level 4}=[level distance=4.5cm, sibling distance=1.25cm]
\begin{tikzpicture}
	[
    grow = right,
    edge from parent/.style = {draw, -latex},
    every state/.style       = {font=\footnotesize},
    sloped    
    ]
  \node [env] {$\epsilon$}
    child { state [env] {1}
      child{ state [leaf] {11}
      	child{ state [leaf] {111}
      		child{ state [leaf] {1111}
      			edge from parent state [below] {1/0.2606}}
      		child{ state [leaf] {1110}
      			edge from parent state [above] {0/0.7394}}
        	edge from parent state [below] {1/0.3744}}
      	child{ state [leaf] {110}
      		child{ state [leaf] {1101}
      			edge from parent state [below] {1/0.4364}}
      		child{ state [leaf] {1100}
      			edge from parent state [above] {0/0.5636}}
        	edge from parent state [above] {0/0.6256}}
      	edge from parent state [below] {1/0.2610}}
      child{ state [env] {10}
      	child{ state [leaf] {101}
      		child{ state [leaf] {1011}
      			edge from parent state [below] {1/0.7417}}
      		child{ state [leaf] {1010}
      			edge from parent state [above] {0/0.2583}}
        	edge from parent state [below] {1/0.3597}}
      	child{ state [leaf] {100}
      		child{ state [leaf] {1001}
      			edge from parent state [below] {1/0.5000}}
      		child{ state [leaf] {1000}
      			edge from parent state [above] {0/0.5000}}
        	edge from parent state [above] {0/0.6403}}
      	edge from parent state [above] {0/0.7390}}
      edge from parent state [below] {1/0.3724} }
    child { state [env] {0}
      child{ state [env] {01}
       	child{ state [leaf] {011}
      		child{ state [leaf] {0111}
      			edge from parent state [below] {1/0.4425}}
      		child{ state [leaf] {0110}
      			edge from parent state [above] {0/0.5575}}
         	edge from parent state [below] {1/0.2210}}
       	child{ state [leaf] {010}
      		child{ state [leaf] {0101}
      			edge from parent state [below] {1/0.3380}}
      		child{ state [leaf] {0100}
      			edge from parent state [above] {0/0.6620}}
         	edge from parent state [above] {0/0.7790}}
      	edge from parent state [below] {1/0.4385}}
      child{ state [leaf] {00}
       	child{ state [leaf] {001}
      		child{ state [leaf] {0011}
      			edge from parent state [below] {1/0.2000}}
      		child{ state [leaf] {0010}
      			edge from parent state [above] {0/0.8000}}
         	edge from parent state [below] {1/0.5000}}
       	child{ state [leaf] {000}
      		child{ state [leaf] {0001}
      			edge from parent state [below] {1/0.5000}}
      		child{ state [leaf] {0000}
      			edge from parent state [above] {0/0.5000}}
         	edge from parent state [above] {0/0.5000}}
      	edge from parent state [above] {0/0.5615}}
      edge from parent state [above] {0/0.6276} };
\end{tikzpicture}
\caption{Rooted Tree with Probabilities $\mathcal{S}$ for the Tri-Shift Example after the sixth iteration. \label{fig:trishifttree6}}
\end{figure}

\begin{figure}[h]
\centering
\tikzstyle{level 1}=[level distance=2.5cm, sibling distance=11.5cm]
\tikzstyle{level 2}=[level distance=2.5cm, sibling distance=5.5cm]
\tikzstyle{level 3}=[level distance=3.5cm, sibling distance=3cm]
\tikzstyle{level 4}=[level distance=4.5cm, sibling distance=1.25cm]
\begin{tikzpicture}
	[
    grow = right,
    edge from parent/.style = {draw, -latex},
    every state/.style       = {font=\footnotesize},
    sloped    
    ]
  \node [env] {$\epsilon$}
    child { state [env] {1}
      child{ state [env] {11}
      	child{ state [leaf] {111}
      		child{ state [leaf] {1111}
      			edge from parent state [below] {1/0.2606}}
      		child{ state [leaf] {1110}
      			edge from parent state [above] {0/0.7394}}
        	edge from parent state [below] {1/0.3744}}
      	child{ state [leaf] {110}
      		child{ state [leaf] {1101}
      			edge from parent state [below] {1/0.4364}}
      		child{ state [leaf] {1100}
      			edge from parent state [above] {0/0.5636}}
        	edge from parent state [above] {0/0.6256}}
      	edge from parent state [below] {1/0.2610}}
      child{ state [env] {10}
      	child{ state [leaf] {101}
      		child{ state [leaf] {1011}
      			edge from parent state [below] {1/0.7417}}
      		child{ state [leaf] {1010}
      			edge from parent state [above] {0/0.2583}}
        	edge from parent state [below] {1/0.3597}}
      	child{ state [leaf] {100}
      		child{ state [leaf] {1001}
      			edge from parent state [below] {1/0.5000}}
      		child{ state [leaf] {1000}
      			edge from parent state [above] {0/0.5000}}
        	edge from parent state [above] {0/0.6403}}
      	edge from parent state [above] {0/0.7390}}
      edge from parent state [below] {1/0.3724} }
    child { state [env] {0}
      child{ state [env] {01}
       	child{ state [leaf] {011}
      		child{ state [leaf] {0111}
      			edge from parent state [below] {1/0.4425}}
      		child{ state [leaf] {0110}
      			edge from parent state [above] {0/0.5575}}
         	edge from parent state [below] {1/0.2210}}
       	child{ state [leaf] {010}
      		child{ state [leaf] {0101}
      			edge from parent state [below] {1/0.3380}}
      		child{ state [leaf] {0100}
      			edge from parent state [above] {0/0.6620}}
         	edge from parent state [above] {0/0.7790}}
      	edge from parent state [below] {1/0.4385}}
      child{ state [leaf] {00}
       	child{ state [leaf] {001}
      		child{ state [leaf] {0011}
      			edge from parent state [below] {1/0.2000}}
      		child{ state [leaf] {0010}
      			edge from parent state [above] {0/0.8000}}
         	edge from parent state [below] {1/0.5000}}
       	child{ state [leaf] {000}
      		child{ state [leaf] {0001}
      			edge from parent state [below] {1/0.5000}}
      		child{ state [leaf] {0000}
      			edge from parent state [above] {0/0.5000}}
         	edge from parent state [above] {0/0.5000}}
      	edge from parent state [above] {0/0.5615}}
      edge from parent state [above] {0/0.6276} };
\end{tikzpicture}
\caption{Rooted Tree with Probabilities $\mathcal{S}$ for the Tri-Shift Example after the seventh iteration. \label{fig:trishifttree7}}
\end{figure}


\section{Tree Termination\label{sec:treeterm}}

Unlike CRISSiS, the algorithms developed in this work need the rooted tree with probabilities to end, otherwise it will keep going without end. The rooted tree with probabilities raised from the sub-sequence probabilities will end in the $L$th level whose states will have outgoing edges initially pointing out to nowhere. Two termination criteria were implemented and in chapters 4 and 5 it will be shown in which cases each of these terminations should be applied. The termination criteria are the D-Markov Termination and $\Omega$ Termination.

\subsection{D-Markov Termination}

This is the simplest termination criterion. It will aim to form a D-Markov Machine with the states in the last level. This means that a state labeled with $\omega = \sigma_0\sigma_1\ldots\sigma_L \in \Sigma^L$ will have its $\tau \in \Sigma$ labeled edge connected to the state labeled with $\sigma_1\sigma_2\ldots\sigma_L\tau$ for each $\tau \in \Sigma$. This is shown in Algorithm \ref{alg:dmarkterm}.

This termination does not rely on the system's memory, preferring to count on the amount of cases that are captured in a D-Markov machine and applying the subsequent algorithms to reduce its size. It is a better option when the system to be modeled does not synchronize. 

  \begin{algorithm}
  \caption{dmarkov-termination($\mathcal{S}, L$)\label{alg:dmarkterm}}
    \begin{algorithmic}[1]
      \Procedure{Terminate}{}
      	\State $\Psi \gets \{n \in \mathcal{S}$ if $n$ in level $L\}$
      	\For{$p \in \Psi$}
      		\State Given that $p$.label is $\sigma_0\sigma_1\ldots\sigma_L$
      		\For{$\tau \in \Sigma$}
      			\State $\delta(\tau, p) \gets \sigma_1\sigma_2\ldots\sigma_L\tau$
      		\EndFor
      	\EndFor
      \EndProcedure
    \end{algorithmic}
  \end{algorithm}
  
\textbf{TO DO:}Figure \ref{fig:trishiftdmark} shows the rooted tree with probabilities from the Trishift example with $L=3$ and the D-Markov termination.

%\begin{figure}
%\centering
%\begin {tikzpicture}[-latex ,auto ,node distance =2 cm and 2 cm ,on grid ,
%semithick ,
%state/.style ={ circle , draw = black , text=black , minimum width =1 cm}]
%\node[state] (root)
%{$\epsilon$};
%\node[state] (0) [above right=of root] {$0$};
%\node[state] (1) [below right =of root] {$1$};
%\node[state] (00) [above right =of 0] {$00$};
%\node[state] (01) [right =of 0] {$01$};
%\node[state] (10) [right =of 1] {$10$};
%\node[state] (11) [below right =of 1] {$11$};
%\node[state] (000) [above =of 00] {$000$};
%\node[state] (001) [above right =of 00] {$001$};
%\node[state] (010) [above right =of 01] {$010$};
%\node[state] (011) [right =of 01] {$011$};
%\node[state] (100) [right =of 10] {$100$};
%\node[state] (101) [below right =of 10] {$101$};
%\node[state] (110) [below right =of 11] {$110$};
%\node[state] (111) [below =of 11] {$111$};
%\path (root) edge state[above] {$0$} (0);
%\path (root) edge state[below] {$1$} (1);
%\path (0) edge state[above] {$1$} (00);
%\path (0) edge state[below] {$0$} (01);
%\path (1) edge state[above] {$0$} (10);
%\path (1) edge state[below] {$1$} (11);
%\path (00) edge state[left] {$0$} (000);
%\path (00) edge state[below] {$1$} (001);
%\path (01) edge state[above] {$0$} (010);
%\path (01) edge state[below] {$1$} (011);
%\path (10) edge state[above] {$0$} (100);
%\path (10) edge state[below] {$1$} (101);
%\path (11) edge state[above] {$0$} (110);
%\path (11) edge state[left] {$1$} (111);
%\path (000) [loop left] edge state[left] {$0$} (000);
%\path (000) edge state[above] {$1$} (001);
%\path (001) edge state[right] {$0$} (010);
%\path (001) [bend left] edge state[right] {$1$} (011);
%\path (010) [bend left] edge state[right] {$0$} (100);
%\path (010) [bend right=1.0cm] edge state[below =0.15 cm] {$1$} (101);
%\path (011) [bend left] edge state[below =0.15 cm] {$0$} (110);
%\path (011) [bend left] edge state[below =0.15 cm] {$1$} (111);
%\path (100) [bend left] edge state[below =0.15 cm] {$0$} (000);
%\path (100) [bend left] edge state[below =0.15 cm] {$1$} (001);
%\path (101) [bend left] edge state[below =0.15 cm] {$0$} (010);
%\path (101) [bend left] edge state[below =0.15 cm] {$1$} (011);
%\path (110) [bend right] edge state[right] {$0$} (100);
%\path (110) edge state[right] {$1$} (101);
%\path (111) [loop left] edge state[left] {$1$} (111);
%\path (111) edge state[below] {$0$} (110);
%\end{tikzpicture}
%\caption{Tri-Shift rooted tree with probabilities with D-Markov termination and $L=3$.\label{fig:trishiftdmark}}
%\end{figure}

\subsection{$\Omega$ Termination}

This termination criteria relies more on using synchronization words, which means it is more suitable to systems that synchronize and that have some memory. For each state $n$ in level $L+1$, it checks via statistical test if $n$ has similar morph to any of the synchronization words states. If it is not, it subsequently tests with the morphs of each extension of synchronization words up to length $L$. If any of these tests succeeds, the state $m$ in level $L$ that has $\delta(\tau,m) = n$ for $\tau \in \Sigma$ will have this edge reassigned for the state with which the test was successful. In case no test passes, the D-Markov criteria is used for $m$. This is shown in Algorithm \ref{alg:omegaterm} whose inputs are the rooted tree with probabilities $\mathcal{S}$, the desired last level $L$ and a list of synchronization words $\Omega_{syn}$.  

  \begin{algorithm}
  \caption{$\Omega$-termination($\mathcal{S}, L, \Omega_{syn}$)\label{alg:omegaterm}}
    \begin{algorithmic}[1]
      \Procedure{Terminate}{}
      	\State $\Psi \gets \{p \in \mathcal{S}$ if $n$ in level $L\}$
      	\For{$m \in \Psi$}
      		\State next = NULL
      		\For{$\tau \in \Sigma$}
      			\State $n = \delta(\tau,m)$
      			\For{$\omega \in \Omega_{syn}$}
      				\State $r \gets \mathcal{V}(n) = \mathcal{V}(\omega)$
      				\If{$r = True$}
      					\State next $\gets \omega$
      					\State \textbf{break}
      				\EndIf
      			\EndFor
      			\If{next = NULL}
      				\State $\eta \gets \{$All extensions of $\omega$ up to length $L, \forall \omega \in \Omega_{syn}\}$
      				\For{$e \in \eta$}
      				\State $r \gets \mathcal{V}(n) = \mathcal{V}(e)$
      					\If{$r = True$}
      						\State next $\gets e$
      						\State \textbf{break}
      					\EndIf
      				\EndFor
      			\EndIf
      			\If{next = NULL}
      				\State Given that $m$.label = $\sigma_0\ldots\sigma_L$
      				\State next = $\sigma_1\ldots\sigma_L\tau$
      			\EndIf
      			\State $\delta(\tau,m) \gets$ next
      		\EndFor
      	\EndFor
      \EndProcedure
    \end{algorithmic}
  \end{algorithm}

\section{Graph Construction}

Two different methods can be used to retrieve the final PFSA: the $\aleph_0$ and $\aleph_1$ algorithms. As with the termination criteria, each one of them is better suited for a specific type of application. The $\aleph_0$ algorithm is less dependent on synchronization words and performs better in systems that do not synchronize. The $\aleph_1$ algorithm is faster, but heavily relies on synchronization words, so it tends to construct better PFSA when the original system synchronizes. Both algorithms take as inputs a terminated rooted tree with probabilities (using one of the criteria from Section \ref{sec:treeterm}) $\mathcal{S}$ and a list of synchronization words $\Omega_{syn}$.

\subsection{$\aleph_0$ Algorithm}

This algorithm starts by taking only the first element of $\Omega_{syn}$ as $\omega$. If the system has no synchronization words, $\omega$ is then the root state $\epsilon$. The algorithm will then expand the children states of $\omega$ and compare them with $\omega$ via statistical test. If the test passes, the states are grouped together in the same partition. If not, a new partition is created for that state. This procedure is then repeated for each subsequent state until all states of $\mathcal{S}$ are in one partition. These partitions are then used as an initial partition for the Moore or Hopcroft Algorithms. This is shown in Algorithm \ref{alg:aleph0}.

By applying this algorithm, states that have similar morphs are grouped together as they potentially produce the same sequences. By applying a graph reduction algorithm after the initial partition, states with similar morphs but distinct languages are then separated, while the ones with same languages are kept together. This procedure reduces the number of redundant states (the ones with same morphs and same languages).

\begin{algorithm}
  \caption{$\aleph_0$($\mathcal{S}, \Omega_{syn}$)\label{alg:aleph0}}
    \begin{algorithmic}[1]
      \Procedure{}{}
      	\If{$\Omega_{syn} \neq \emptyset$}
      		\State $\omega \gets \Omega_{syn}[0]$
      	\Else
      		\State $\omega \gets \epsilon$
      	\EndIf
      	\State $P \gets \{\omega\}$
      	\State $\mathcal{P} \gets \{P\}$
      	\State $Q \gets \{\delta(\sigma,\omega), \forall \sigma \in \Sigma\}$
      	\For{$q \in Q$}
      		\State $r \gets$ False
      		\For{$p \in \mathcal{P}$}
      			\State $r \gets \mathcal{V}(q) = \mathcal{V}(p[0])$
      			\If{$r =$ True}
      				\State $p \gets p\bigcup\{q\}$
      				\State \textbf{break}
      			\EndIf
      		\EndFor
      		\If{$r =$ False}
      			\State $R \gets \{q\}$
      			\State $\mathcal{P} \gets \mathcal{P}\bigcup\{R\}$
      		\EndIf 
      		\State $Q \gets Q\bigcup\{\delta(\sigma,q),\forall \sigma\in\Sigma|\delta(\sigma,q)$ not in any $p\in\mathcal{P}\}$
      	\EndFor
      	\State $G \gets$ GraphReduction($\mathcal{P}$)
      	\State \textbf{return} $G$
      \EndProcedure
    \end{algorithmic}
  \end{algorithm}

\begin{algorithm}
  \caption{$\aleph$($\mathcal{S}, \Omega_{syn}$)\label{alg:aleph}}
    \begin{algorithmic}[1]
      \Procedure{}{}
      	\If{$\Omega_{syn} \neq \emptyset$}
      		\State $\mathcal{S} \gets$ \textit{omegaTermination}($\mathcal{S}$)
	      	\State $Q_0 \gets \Omega_{syn}$
	      	\State $Q_1 \gets \emptyset$
	      	\While{$Q_0 \neq \emptyset$}
	      		\State $q \gets Q_0.pop()$
	      		\For{$\sigma \in \Sigma$}
	      			\State $q' \gets \delta(q,\sigma)$
	      			\If{for some $\omega \in \Omega_{syn}, \omega$ is a suffix of $q'$}
	      				\State $\delta(\sigma,q) \gets \omega$
	      			\Else
	      				\If{$q' \notin Q_0$ and $q' \notin Q_1$}
	      					\State $Q_0 \gets Q_0\bigcup\{q'\}$
	      				\EndIf 
	      			\EndIf
	      			\State $Q_1 \gets Q_1\bigcup\{q\}$
	      		\EndFor
	      	\EndWhile	      	
      		\State $Q \gets \{\delta(\sigma,\omega), \forall \sigma \in \Sigma, \forall \omega \in \Omega_{syn}\}$
      	\Else
      		\State $\mathcal{S} \gets$ \textit{dmarkovTermination}($\mathcal{S}$)
      		\State $Q_1 \gets \{\epsilon\}$
      		\State $Q \gets \{\delta(\sigma,\epsilon), \forall \sigma \in \Sigma\}$
      	\EndIf
      	\State $\mathcal{P} \gets \{Q_1\}$
      	\For{$q \in Q$}
      		\State $r \gets$ False
      		\For{$p \in \mathcal{P}$}
      			\State $r \gets$ \textit{statisticalTest}($q, p[0]$)
      			\If{$r =$ True}
      				\State $p \gets p\bigcup\{q\}$
      				\State \textbf{break}
      			\EndIf
      		\EndFor
      		\If{$r =$ False}
      			\State $R \gets \{q\}$
      			\State $\mathcal{P} \gets \mathcal{P}\bigcup\{R\}$
      		\EndIf 
      		\State $Q \gets Q\bigcup\{\delta(\sigma,q),\forall \sigma\in\Sigma|\delta(\sigma,q)$ not in any $p\in\mathcal{P}\}$
      	\EndFor
      	\State \#\# The following function can be either Moore or Hopcroft
      	\State $G \gets$ GraphReduction($\mathcal{P}$)
      	\State \textbf{return} $G$
      \EndProcedure
    \end{algorithmic}
  \end{algorithm}


\subsection{$\aleph_1$ Algorithm}

The $\aleph_1$ algorithm is similar to $\aleph_0$, but it includes a step prior to creating the initial partition for the graph reduction algorithm in order to make a smaller initial partition, which, in turn, makes the graph reduction faster. This step uses all synchronization words in $\Omega_{syn}$ as starting points and checks if any of them has an edge pointing to a state whose label has a synchronization word as suffix. If it has, this edge is reassigned to point to that synchronization word. This procedure is then repeated for each subsequent state in $\mathcal{S}$. Words ending in synchronization words will always point again to the synchronization word state. This procedure reduces the number of states as anything ending with a synchronization word and its extensions will not be used anymore. As the following steps have their complexities depending on number of states, this will speed up the rest of the process.

Once this is done, the rest of the algorithm will repeat $\aleph_0$: starting from the synchronization words, its children will have their morphs compared and partitions will be created following this criterion. When the initial partition is finished, a graph reduction algorithm is applied. Algorithm $\aleph_1$ is shown in Algorithm \ref{alg:aleph1}.

\begin{algorithm}
  \caption{$\aleph_1$($\mathcal{S}, \Omega_{syn}$)\label{alg:aleph1}}
    \begin{algorithmic}[1]
      \Procedure{}{}
      	\State $Q_0 \gets \Omega_{syn}$
      	\State $Q_1 \gets \emptyset$
      	\While{$Q_0 \neq \emptyset$}
      		\State $q \gets Q_0.pop()$
      		\For{$\sigma \in \Sigma$}
      			\State $q' \gets \delta(q,\sigma)$
      			\If{for some $\omega \in \Omega_{syn}, \omega$ is a suffix of $q'$}
      				\State $\delta(\sigma,q) \gets \omega$
      			\Else
      				\If{$q' \notin Q_0$ and $q' \notin Q_1$}
      					\State $Q_0 \gets Q_0\bigcup\{q'\}$
      				\EndIf 
      			\EndIf
      			\State $Q_1 \gets Q_1\bigcup\{q\}$
      		\EndFor
      	\EndWhile
      	\State \textit{$\#\#$ From here on, the algorithm is a slight variation of $\aleph_0\#\#$}
      	\State $\mathcal{P} \gets \{\{\omega\}, \forall \omega \in \Omega_{syn}\}$
      	\State $Q \gets \{\delta(\sigma,\omega), \forall \sigma \in \Sigma, \forall \omega \in \Omega_{syn}\}$
      	\For{$q \in Q$}
      		\State $r \gets$ False
      		\For{$p \in \mathcal{P}$}
      			\State $r \gets \mathcal{V}(q) = \mathcal{V}(p[0])$
      			\If{$r =$ True}
      				\State $p \gets p\bigcup\{q\}$
      				\State \textbf{break}
      			\EndIf
      		\EndFor
      		\If{$r =$ False}
      			\State $R \gets \{q\}$
      			\State $\mathcal{P} \gets \mathcal{P}\bigcup\{R\}$
      		\EndIf 
      		\State $Q \gets Q\bigcup\{\delta(\sigma,q),\forall \sigma\in\Sigma|\delta(\sigma,q)$ not in any $p\in\mathcal{P}\}$
      	\EndFor
      	\State $G \gets$ GraphReduction($\mathcal{P}$)
      	\State \textbf{return} $G$
      \EndProcedure
    \end{algorithmic}
  \end{algorithm}


%\section{Complete Algorithm}
%
%The final algorithm consists of the steps presented in the previous sections. The input is the original sequence \textit{S} and the algorithm outputs a PFSA.
%
%\begin{enumerate}
%\item[1] Find synchronization words from sequence \textit{S};
%\item[2] Apply a termination criterion for the rooted tree with probabilities $\mathcal{S}$ based on \textit{S};
%	\begin{enumerate}
%	\item Use D-Markov Termination if no synchronization words were found;
%	\item Use $\Omega$ if synchronization words were found;
%	\end{enumerate}
%\item[3] Apply a PFSA construction algorithm ($\aleph_0$ or $\aleph_1$).
%\end{enumerate}

\section{Time Complexity}
