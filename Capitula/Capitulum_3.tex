\chapter{Algorithm Description}\label{cap:3}

\tikzset{
  treenode/.style = {shape=circle,
                     draw, align=center,
                     top color=white},
  root/.style     = {treenode, font=\ttfamily\normalsize},
  env/.style      = {treenode, font=\ttfamily\normalsize},
  leaf/.style    = {treenode,font=\ttfamily\normalsize, bottom color=red}
}

{\lettrine[loversize=0.25,findent=0.2em,nindent=0em]{I}{n} this chapter, the proposed PFSA construction algorithm to model a dynamical system from its output sequence \textit{S} is presented. The first section discusses an algorithm to find synchronization words which has lower complexity than the brute force method used by CRISSiS. Later, the PFSA construction algorithm is shown. It is further divided in two parts: the leaf connection, which makes sure that all states have outgoing edges and the full ALEPH algorithm which creates the final PFSA for the provided parameters. 

Thus, the proposed algorithm consists of the following three steps: 


\begin{enumerate}
\item[1] Find synchronization words from sequence \textit{S};
\item[2] Apply a leaf connection criterion for the rooted tree with probabilities $\mathcal{S}$ based on \textit{S};
%	\begin{enumerate}
%	\item Use D-Markov Termination if no synchronization words were found;
%	\item Use $\Omega$ if synchronization words were found;
%	\end{enumerate}
\item[3] Apply the ALEPH algorithm for PFSA construction.
\end{enumerate}

\section{A New Algorithm for Finding Synchronization Words\label{sec:findsynch}}

Given a sequence \textit{S} of length \textit{N} over an alphabet $\Sigma$ generated by a dynamical system, we introduce in this section an algorithm to find possible synchronization words in \textit{S}. The CRISSiS method uses (\ref{eq:practsynchword}) for an extensive, brute force search.  The proposed algorithm uses data structures in order to speed up the process. This implies using a structured search to realize less statistical tests, which reduces the time complexity of the algorithm, while also finding not only just one synchronization word, but all of them up to a given length \textit{W}.

The proposed algorithm uses a rooted tree with probabilities $\mathcal{S}$ over an alphabet $\Sigma$ to search for synchronization words. At the beginning of the algorithm, all states of $\mathcal{S}$ are considered valid candidates to be synchronization words. A search is performed in $\mathcal{S}$ starting by its root using a statistical test (which compares two state morphs via a test such as $\chi^2$ or Kolmogorov-Smirnov for a given confidence level $\alpha$) to determine whether a state should be expanded. The way the tree is explored guarantees that a state is only tested against other states that have it as a suffix. When a test fails, an expansion algorithm is used to determine how the next states are to be tested. On the other hand, when the test is successful, the state keeps its status as a valid candidate.

A rooted tree with probabilities (RTP) $\mathcal{S}$ over $\Sigma = \{0, 1\}$ is presented via an example in Figure \ref{fig:rtp}. It consists of a set of states connected by edges. All states have exactly one predecessor (with the exception of the root state, labeled with the empty string $\epsilon$, which has no predecessors). Leaf states ($0, 10$ and $11$ in the example) have no successors, while the other states have $|\Sigma|$ successors as each element of $\Sigma$ labels its outgoing edges. Those edges are also labeled with the probability of leaving the state with that symbol. Each state is labeled with the string formed from concatenating the symbols in the branches in the path from the root to the current state. The probability of reaching a state is given by multiplying the probabilities labeling the branches in the path from the root state to the current state. For example, consider the leaf state \textit{10}. The path taken from the root state $\epsilon$ is first \textit{1} and then \textit{0}. The probability of reaching this state is $P(1)\times P(0|1)$, that is the probability of leaving the root state with 1 (which is $P(1)$) multiplied by the probability of leaving the state 1 with 0 (that is, $P(0|1)$). The edge probabilities of $\mathcal{S}$ are taken from the conditional probabilities of sub-sequences of \textit{S}.

An RTP has its maximum depth \textit{L} ultimately constrained by the length \textit{N} of \textit{S}. It is good to remind that as the chance of sub-sequences occurring gets smaller as their length increases, the statistics of large sub-sequences might be really poor for a given \textit{N}. This means that using a very large \textit{L} implies that the probabilities of states closer to the leaves tend to be unreliable.

\begin{figure}
\centering
\begin{tikzpicture}
  [
    grow                    = right,
    sibling distance        = 3em,
    level distance          = 6em,
    edge from parent/.style = {draw, -latex},
    every state/.style       = {font=\footnotesize},
    sloped
  ]
  \node [root] {$\epsilon$}
    child { node [env] {1}
      child{ node [leaf] {11}
      	edge from parent node [below] {1/P(1$|$1)}}
      child{ node [leaf] {10}
      	edge from parent node [above] {0/P(0$|$1)}}
     edge from parent node [below] {1/P(1)} }
   child { node [leaf] {0}
      edge from parent node [above] {0/P(0)} };
\end{tikzpicture}
\caption{Example of a rooted tree with probabilities. \label{fig:rtp}}
\end{figure}
 
 Another data structure used in the algorithm is a dictionary (also called a hash table) \citep{thomas2001introduction}. A dictionary $d$ is a mapping between two sets $d: X \rightarrow Y$. The elements from $X$ are called the dictionary keys. An entry in the dictionary is the element $y \in Y$ associated to the key $x \in X$ and is denoted by $d[x]$, which is also called the \textit{value} of $x$ in $d$. An entry $d[x]$ might be updated and even deleted from $d$.
 
As mentioned before, all states of $\mathcal{S}$ start as possible candidates for synchronization words. This is represented by a dictionary called $candidacy$ which takes states as keys. For a given key $k$, $candidacy[k]$ is a boolean value: it is True when $k$ is still a possible synchronization word and False when it is not (i.e. when it failed a statistic test). Thus, $candidacy$ is initialized with a True value for all of its keys. When $candidacy[k] =$ True, $k$ is called a valid state.
 
The concept of a shortest valid suffix (SVS) also needs to be explained as it is important in one of the algorithm steps via an auxiliary function called \textit{shortestValidSuffix}. For a given word $\omega \in \Sigma^*$, its SVS is the state from $\mathcal{S}$ labeled with the shortest word that has $\omega$ as a suffix and it is still a valid candidate for synchronization word. The function \textit{shortestValidSuffix} receives the word $\omega = \sigma_1\sigma_2\ldots\sigma_n \in \Sigma^*$, the tree $\mathcal{S}$ and the dictionary \textit{candidacy} as inputs. First $\omega = \sigma_1\sigma_2\ldots\sigma_n$ is reversed, $\omega_{rev} = \sigma_n\sigma_{n-1}\ldots\sigma_1$. Then, the tree $\mathcal{S}$ is traversed according to $\omega_{rev}$, starting at the root $\epsilon$. \textit{candidacy[$\epsilon$]} is checked and if it is true, $\epsilon$ is returned. If not, the state $\delta(\sigma_n, \epsilon)$ is evaluated. At each level $k$ of $\mathcal{S}$, the current state is $c = \delta^*(\sigma_n\ldots\sigma_{n-k},\epsilon)$. Let $c_{rev}$ be the reversed label of the current candidate (i.e. if $c = \tau_1\tau_2\ldots\tau_m$, $c_{rev} = \tau_m\tau_{m-1}\ldots\tau_1$). If \textit{candidacy}[$c_{rev}$] is True, $c_{rev}$ is returned. If not the next iteration is processed until $\omega_{rev}$ is reached, which means that $\omega$ is its own shortest valid suffix if its candidacy is True or that it has no valid suffix if its candidacy is False.
 
 As an example, take the tree $\mathcal{S}$ represented in Figure \ref{fig:treet}, where the filled states indicate that their candidacy status is True while the white states have them as False. If we wish to check which state is the shortest valid suffix for $\omega = 110$ we first take $\omega_{rev} = 011$ and go to the root. As \textit{candidacy}[$\epsilon$] is False, we go to the next iteration, taking $c = \delta(0, \epsilon) = 0$. The candidacy of $c_{rev} = 0$ is checked, which once again is false and takes us to the next iteration. Now $c = \delta^*(01, \epsilon) = 01$, $c_{rev} = 10$ and \textit{candidacy}[$c_{rev}$] = \textit{candidacy}[$10$] = True and the function returns $c_{rev} = 10$, i.e. $10$ is the shortest valid suffix of $110$.
 
 Along with the \textit{candidacy} dictionary, a second dictionary called \textit{suffixes} is created. It also has the states from $\mathcal{S}$ as keys. The associated value to each key is a list of states for which the key is the shortest valid suffix, i.e. the key state is the shortest state to have a \textit{True} value for its candidacy and also is a suffix for all the word in the associated list.  Another dictionary, $V$ is created to be used in the expansion algorithm and it is explained later in the context of Algorithm \ref{alg:expand}.

To find the synchronization words, Algorithm \ref{alg:findsynchwords} is used. Its inputs are the rooted tree with probabilities $\mathcal{S}$ with maximum depth $L$, the maximum window size $W$, which is a parameter that determines how deep in the tree the algorithm searches. The algorithm starts by creating the queue $\Gamma$ which contains states from $\mathcal{S}$ that are not fully tested for the synchronization word hypothesis during the current iteration. $\Gamma$ is initialized with $\epsilon$. A list $\Theta$ is created and initialized empty. It receives the states from $\mathcal{S}$ which currently have passed the statistical tests. The statistical tests are implemented as either $\chi^2$ or Kolmogorov-Smirnov tests for a given confidence level $\alpha$. This is implemented as the auxiliary function \textit{statisticalTest} which takes two states whose morphs needs to be compared and a confidence level as inputs and returns True if the test passes and False otherwise.

As $\epsilon$ is the only value to be tested in the beginning of the algorithm, only \textit{suffixes}$[\epsilon]$ is initialized with a list of the states  $\sigma \in \Sigma$ as they all have $\epsilon$ as their shortest valid suffix. 

%When a test fails, $\Theta$ is appended to $\Gamma$ and emptied again, as the states in $\Theta$ have to be checked along with other states that might now have them as suffixes. Once all the tests are performed, $\Theta$ is returned as it contains the list of synchronization words by the end of the algorithm.
 
% Three dictionaries are also created. The first one, \textit{candidacy} has already been discussed before. The states from $\mathcal{S}$ are the keys and to each one a boolean value is associated. When a state is still a valid candidate for synchronization word (which means it either had not been tested against its suffixes yet or has passed all the tests up to the current iteration), it has the \textit{True} value associated with it. Once it fails a test and can no longer be considered a valid candidate to be a synchronization word, the associated value becomes \textit{False}. A state for which the \textit{candidacy} value is \textit{True} is called a valid state. At the beginning of the algorithm, all states are valid as they have not been tested yet and their \textit{candidacy} is initialized accordingly.
 
 
 
% The last dictionary, $V$ stores lists of states associated with their shortest valid suffix as key. states should only be queued into $\Gamma$ if they are their own shortest valid suffix. During a call to Algorithm \ref{alg:expand}, which occurs every time a statistical test fails, if a new state to be added in $\Gamma$ is not its own shortest valid suffix, its shortest valid suffix is used as a key in $V$ and this element is associated with it. If later this shortest valid suffix fails a statistical test, all elements associated with it in $V$ have to be checked again to see if now they are their own shortest valid suffixes.
 
%When two states $p, q \in \mathcal{S}$ are compared (with the notation \textit{statisticalTest}($p, q$) it means that their morphs are compared via an appropriate statistical test (such as the $\chi^2$ test or Kolmogorov-Smirnov test) with a predetermined confidence level $\alpha$.
 
  
\begin{figure}
\centering
\tikzstyle{level 1}=[level distance=3cm, sibling distance=4.5cm]
\tikzstyle{level 2}=[level distance=4cm, sibling distance=2.5cm]
\tikzstyle{level 3}=[level distance=4cm, sibling distance=1cm]
\begin{tikzpicture}
	[
    grow = right,
    edge from parent/.style = {draw, -latex},
    every node/.style       = {font=\footnotesize},
    sloped    
    ]
  \node [root] {$\epsilon$}
    child { node [env] {1}
      child{ node [env] {11}
      	child{ node [leaf] {111}
        	edge from parent node [below] {1/$P(1|11)$}}
      	child{ node [leaf] {110}
        	edge from parent node [above] {0/$P(0|11)$}}
      	edge from parent node [below] {1/P(1$|$1)}}
      child{ node [leaf] {10}
      	child{ node [leaf] {101}
        	edge from parent node [below] {1/$P(1|10)$}}
      	child{ node [leaf] {100}
        	edge from parent node [above] {0/$P(0|10)$}}
      	edge from parent node [above] {0/P(0$|$1)}}
      edge from parent node [below] {1/P(1)} }
    child { node [env] {0}
      child{ node [env] {01}
       	child{ node [leaf] {011}
         	edge from parent node [below] {1/$P(1|01)$}}
       	child{ node [leaf] {010}
         	edge from parent node [above] {0/$P(0|01)$}}
      	edge from parent node [below] {1/P(1$|$0)}}
      child{ node [leaf] {00}
       	child{ node [leaf] {001}
         	edge from parent node [below] {1/$P(1|00)$}}
       	child{ node [leaf] {000}
         	edge from parent node [above] {0/$P(0|00)$}}
      	edge from parent node [above] {0/P(0$|$0)}}
      edge from parent node [above] {0/P(0)} };
\end{tikzpicture}
\caption{Example of binary RTP with $L=3$. \label{fig:treet}}
\end{figure}

The main loop then begins. At the start of each iteration, the variable $c$ receives the first element of $\Gamma$ via dequeueing (as $\Gamma$ is a queue, the first element to be inserted into it is the first to be removed) which is represented by the dequeue auxiliary function in line 10 of Algorithm \ref{alg:findsynchwords}. It takes the queue $\Gamma$ as input and returns the elements in its first position. If the label of $c$ is not larger than $W$, a flag $p$ is set to True. If \textit{suffixes}[$c$] is empty, $p$ stays True. Otherwise, each element $\lambda$ of \textit{suffixes}[$c$] goes through the statistical test with $c$ in order to check (\ref{eq:practsynchword}) and $p$ receives the result of \textit{statisticalTest}($c, \lambda, \alpha$). If after all the tests are performed, $p$ retains its True value, $c$ keeps its status as a valid candidate for synchronization word and it is appended at $\Theta$ . If one of the tests fails, $p$ is set to False and no more tests need to be done for $c$. The \textit{candidacy}($c$) is set to False, the list $\Gamma$ and the dictionaries will be expanded according to Algorithm \ref{alg:expand} (which will be explained later) and as each element $\theta \in \Theta$ needs to be tested again for the new elements appended to \textit{suffixes}[$\theta$] after the expansion, all elements of $\Theta$ are queued at the end of $\Gamma$ (using the auxiliary function queue) and then $\Theta$ is set to the empty set. This procedure is repeated until either the queue $\Gamma$ is empty or if all the elements in $\Gamma$ have labels longer than $W$. After one of these conditions is met, it stores $\Theta$ in the list $\Omega_{syn}$, which contains all the elements that passed in all their statistical tests, meaning that they are synchronization words according to (\ref{eq:practsynchword}). $\Omega_{syn}$ is then returned as the final value. 

\begin{algorithm} 
  \caption{findSynchWords($W, \mathcal{S}$)\label{alg:findsynchwords}}
    \begin{algorithmic}[1]
      \Procedure{Initialization}{}
      	\State $\Gamma \gets \{\epsilon \in \mathcal{S}\}$ 
        \State \textit{suffixes}$[\epsilon ] \gets \{\delta (\sigma , \epsilon) \forall \sigma \in \Sigma \}$
        \State $V \gets$ empty dictionary
        \For{$s \in \mathcal{S}$}
        	\State \textit{candidacy}$[s] = $ True
        \EndFor
        \State $\Theta \gets \emptyset$ 
      \EndProcedure	
      \Procedure{MainLoop}{}
      	\While{$\Gamma \neq \emptyset$}
        	\State $\textit{c} \leftarrow$ dequeue$(\Gamma)$
        	\If {length$(c) < W$}
        		\State $p \leftarrow$ True
        		\If {\textit{suffixes}[$c$]$ \neq \emptyset$}
        			\For{\textbf{every} $\lambda \in$ \textit{suffixes}$[c]$}
        				\State $p \leftarrow$ \textit{statisticalTest}($c, \lambda, \alpha)$
        				\If {$p =$ False}
        					\State candidacy$[c] \gets$ False
        					\State expand($c, V, \mathcal{S}, \Gamma,$ candidacy, suffixes$)$
        					\For{\textbf{every} $\theta \in \Theta$}
        						\State queue$(\Gamma,\theta)$
        					\EndFor
        					\State $\Theta \leftarrow \emptyset$
        					\State \textbf{break}
        				\EndIf
        			\EndFor
        		\EndIf
        		\If {$p =$ True}
        			\State $\Theta \gets \Theta \cup \{c\}$
        		\EndIf
        	\EndIf
      	\EndWhile
      	\State $\Omega_{syn} \gets \Theta$
      	\State \textbf{return} $\Omega_{syn}$
      \EndProcedure
    \end{algorithmic}
  \end{algorithm}
  
Algorithm \ref{alg:expand} updates $\Gamma$ and the dictionaries \textit{suffixes} and $V$ after a statistical test fails. Its goal is to take the descendants of the element $c$ that failed the test and queue them into the end of $\Gamma$ and in turn take their descendants, find their SVS and append them to their SVS \textit{suffixes} dictionary entry. There are some caveats: for an element to be queued into $\Gamma$, it needs to be its own SVS, otherwise it means that there are shorter states that need to be checked first. Given an element $d$ that is a descendant of $c$ is not its own SVS (call it $\zeta$), it is appended to the list $V[\zeta]$. This is done so if in a later iteration $\zeta$ (which should be in $\Gamma$) fails its test, $d$ has the opportunity to check again if it became its own SVS so it might be queued into $\Gamma$.

First, a list $\Psi$ with all the descendants of the state $c$ is created. This list holds the elements that need to be checked if they can be queued into $\Gamma$. They will be queued if they are their own SVS.  The dictionary $V$ uses states of $\mathcal{S}$ as keys (for a given key $k$ $V[k]$ is a list of states that have $k$ as SVS). When an element is not its own SVS it cannot be added to $\Gamma$ and so it is added to a list in $V$. In a later call to Algorithm \ref{alg:expand} it might have become its own SVS and so it has to be checked again. If there is a list associated to $c$ in $V$, all its elements are appended to $\Psi$. The entry $V[c]$ is then deleted as it no longer has a use.

The next step is to check if each element $d$ in $\Psi$ are their own SVS using the \textit{shortestValidSuffix} function. This function will return a state $\zeta$ which is the SVS of $d$. If $d = \zeta$, $d$ is queued at the end of $\Gamma$. After this, for each descendant $t$ of $d$, $t$ has its SVS $\tau$ found and \textit{suffixes}[$\tau$] has $t$ appended to it, as now $t$ has to be checked against $\tau$.

When $\zeta \neq d$, $V[\zeta]$ has $d$ appended to it. Later on, if $\zeta$ fails one of its tests, $d$ has to be checked again to see if it is now its own SVS.

% If they are not, this means that there are shorter words that need to be checked before them. In this case, the entry $V[\zeta]$ is created, where $\zeta$ is the SVS of $d$, and $d$ is stored in this list. Once this $\zeta$ is tested in Algorithm \ref{alg:findsynchwords} and if it fails its statistical test, this $d$ will be checked again to see if it is its SVS.
%
%On the other hand, if $\zeta = d$, this element is then added to the end of the queue $\Gamma$ and it will be later dequeued and tested.  The last step is to update the suffix dictionary so there are new elements to be compared with their suffixes. The list of all the descendants of $\zeta$ is iterated. The shortest valid suffix \textit{short} of each of its elements $t$ is found and used as an entry of \textit{suffixes}, such that \textit{suffixes}[short] appends $t$.
  
  \begin{algorithm}[t]
  \caption{expand($c, V, \mathcal{S},\Gamma,$ candidacy, suffixes)\label{alg:expand}}
    \begin{algorithmic}[1]
      \Procedure{Expand $\Gamma$}{}
      	\State $\Psi \gets \{\delta(\sigma,c),\forall \sigma \in \Sigma\}$
      	\If {$c$ is a key of $V$}
      		\State $\Psi \gets \Psi \cup V[c]$
      		\State delete $V[c]$
      	\EndIf
      	\For{\textbf{every} $d \in \Psi$}
      		\State $\zeta \gets $ \textit{shortestValidSuffix}$(\mathcal{S}, d,$ \textit{candidacy}$)$
      		\If{$\zeta = d$}
      			\State queue($\Gamma$, $\zeta$)
      			\For{$t \in\{\delta(\sigma, \zeta) \forall \sigma \in \Sigma\}$}
      				\State $\tau \gets $ \textit{shortestValidSuffix}$(\mathcal{S}, t,$ \textit{candidacy}$)$
      				\State \textit{suffixes}$[\tau] \gets$ \textit{suffixes}$[\tau] \cup t$
      			\EndFor
      		\Else
      			\State $V[\zeta] \gets V[\zeta]\cup\{d\}$
      		\EndIf
      	\EndFor
      \EndProcedure
    \end{algorithmic}
  \end{algorithm}

\subsection{An Example}

To illustrate how the algorithm works, the Tri-Shift as it can be compared to CRISSiS in Section \ref{sec:crissis}. All statistical tests in this section use the $\chi^2$ test with $\alpha = 0.95$. The initial RTP with $L = 4$ is shown in Figure \ref{fig:trishifttree0}. We consider $W=3$.  The queue $\Gamma$ is initialized with the root of $\mathcal{S}$. The dictionary \textit{suffixes} is initialized with  \textit{suffixes}[$\epsilon$] = \{0, 1\}. $V$ is initialized as an empty dictionary, $\Theta$ is initialized as an empty list and all the states start with their candidacy set to True.

As $\Gamma$ is not empty, it is dequeued and $c = \epsilon$, which has a label length of zero and is shorter than $W = 3$. It then proceeds to iterate through \textit{suffixes}[$c$] = \textit{suffixes}[$\epsilon$] = $\{0, 1\}$ and $p$ is set to true. It first compares \textit{statisticalTest}$(\epsilon, 0)$. As the morphs are [0.6276, 0.3274] and [0.5615, 0.4385], the test fails, which means $\epsilon$ candidacy is set to False and the expansion algorithm is called. 

The list $\Psi$ is initialized with the direct descendants of $c = \epsilon$, that is $\Psi = \{0, 1\}$. $V[\epsilon]$ is empty and can be disregarded. It is easy to check that all elements in $\Psi$ are their own shortest valid suffixes after $\epsilon$ candidacy becomes false (seen in Figure \ref{fig:trishifttree1}). This means both of them are queued into $\Gamma$, so that $\Gamma = \{0, 1\}$. For both 0 and 1, they are their direct descendants shortest valid suffixes, which means that suffixes[0] = \{00, 10\} and suffixes[1] = \{01, 11\}. The expansion algorithm returns to the synchronization algorithm. The list $\Theta$ is appended to the end of $\Gamma$, but as it is currently empty it does not change $\Gamma$. This ends the first iteration. 

\begin{figure}[t]
\centering
\tikzstyle{level 1}=[level distance=2.5cm, sibling distance=11.5cm]
\tikzstyle{level 2}=[level distance=2.5cm, sibling distance=5.5cm]
\tikzstyle{level 3}=[level distance=3.5cm, sibling distance=3cm]
\tikzstyle{level 4}=[level distance=4.5cm, sibling distance=1.25cm]
\begin{tikzpicture}
	[
    grow = right,
    edge from parent/.style = {draw, -latex},
    every node/.style       = {font=\footnotesize},
    sloped    
    ]
  \node [leaf] {$\epsilon$}
    child { node [leaf] {1}
      child{ node [leaf] {11}
      	child{ node [leaf] {111}
      		child{ node [leaf] {1111}
      			edge from parent node [below] {1/0.2606}}
      		child{ node [leaf] {1110}
      			edge from parent node [above] {0/0.7394}}
        	edge from parent node [below] {1/0.3744}}
      	child{ node [leaf] {110}
      		child{ node [leaf] {1101}
      			edge from parent node [below] {1/0.4364}}
      		child{ node [leaf] {1100}
      			edge from parent node [above] {0/0.5636}}
        	edge from parent node [above] {0/0.6256}}
      	edge from parent node [below] {1/0.2610}}
      child{ node [leaf] {10}
      	child{ node [leaf] {101}
      		child{ node [leaf] {1011}
      			edge from parent node [below] {1/0.7417}}
      		child{ node [leaf] {1010}
      			edge from parent node [above] {0/0.2583}}
        	edge from parent node [below] {1/0.3597}}
      	child{ node [leaf] {100}
      		child{ node [leaf] {1001}
      			edge from parent node [below] {1/0.5000}}
      		child{ node [leaf] {1000}
      			edge from parent node [above] {0/0.5000}}
        	edge from parent node [above] {0/0.6403}}
      	edge from parent node [above] {0/0.7390}}
      edge from parent node [below] {1/0.3724} }
    child { node [leaf] {0}
      child{ node [leaf] {01}
       	child{ node [leaf] {011}
      		child{ node [leaf] {0111}
      			edge from parent node [below] {1/0.4425}}
      		child{ node [leaf] {0110}
      			edge from parent node [above] {0/0.5575}}
         	edge from parent node [below] {1/0.2210}}
       	child{ node [leaf] {010}
      		child{ node [leaf] {0101}
      			edge from parent node [below] {1/0.3380}}
      		child{ node [leaf] {0100}
      			edge from parent node [above] {0/0.6620}}
         	edge from parent node [above] {0/0.7790}}
      	edge from parent node [below] {1/0.4385}}
      child{ node [leaf] {00}
       	child{ node [leaf] {001}
      		child{ node [leaf] {0011}
      			edge from parent node [below] {1/0.2000}}
      		child{ node [leaf] {0010}
      			edge from parent node [above] {0/0.8000}}
         	edge from parent node [below] {1/0.5000}}
       	child{ node [leaf] {000}
      		child{ node [leaf] {0001}
      			edge from parent node [below] {1/0.5000}}
      		child{ node [leaf] {0000}
      			edge from parent node [above] {0/0.5000}}
         	edge from parent node [above] {0/0.5000}}
      	edge from parent node [above] {0/0.5615}}
      edge from parent node [above] {0/0.6276} };
\end{tikzpicture}
\caption{Input Rooted Tree with Probabilities $\mathcal{S}$ for the Tri-Shift Example. \label{fig:trishifttree0}}
\end{figure}

At the beginning of the next iteration $\mathcal{S}$ is shown in \ref{fig:trishifttree1}, $\Gamma = \{0, 1\}$ and when it is dequeued, $c = 0$, whose label is still shorter than $W$. The list \textit{suffixes}[$0$] $= \{00, 10\}$ has each of its elements tested. First to be tested is $00$ and \textit{statisticalTest}$(0,00)$ returns False as $\mathcal{V}(0) = [0.5615, 0.4385]$ diverges significantly from $\mathcal{V}(00) = [0.5, 0.5]$. This means that \textit{candidacy}[$0$] is set to False and the expansion algorithm is called.

For $c = 0$, the expansion algorithm has $\Psi = \{00, 01\}$ and $0$ is not among the keys of $V$, so no other elements are appended to $\Psi$. First, the SVS is checked for $00$ and by examining the tree, it is observed that it is its own shortest valid suffix. This means that $00$ is queued into $\Gamma$. Its children, $000$ and $001$ have $00$ and $1$ as shortest valid suffixes, so the \textit{suffixes} dictionary is updated to \textit{suffixes}[$000$] = $\{000\}$ and suffixes[$1$] = $\{01, 11, 001\}$. Next, the shortest valid suffix of $01$ is shown to be $1$, which means it is not its own shortest valid suffix. This means it has to be appended to $V[1]$, which makes it $V[1] = \{01\}$. The empty list $\Theta$ is once again appended to $\Gamma$ and then emptied. 

In the beginning of the next iteration, we have $\Gamma = \{1, 000\}$, $V[1] = \{01\}$, $\Theta = \emptyset$, suffixes[$1$] = $\{01, 11, 001\}$, suffixes[$00$] = $\{000\}$ and $mathcal{S}$  is shown in Figure \ref{fig:trishifttree2}. $\Gamma$ is dequeued and $c = 1$, \textit{suffixes}[$1$] = $\{01, 11, 001\}$ is iterated through. First, \textit{statisticalTest}$(1,01)$ is checked to be false ($[0.779, 0.221]$ against $[0.739, 0.261]$) making \textit{candidacy}[$1$] = False and the call to the expansion algorithm.

In the expansion algorithm, $\Psi = \{10, 11\}$ and it is appended of $01$ because $V[1] = \{01\}$, making $\Psi = \{10, 11, 01\}$. Now that both \textit{candidacy}[$0$] = \textit{candidacy}[$1$] = False, all of them are their own shortest valid suffixes and they are their children nodes' shortest valid suffixes. Thus, $\Gamma = \{00, 01, 10, 11\}$ and \textit{suffixes}[$00$] = $\{000, 100\}$, \textit{suffixes}[$01$] = $\{001, 101\}$, \textit{suffixes}[$10$] = $\{010, 110\}$ and \textit{suffixes}[$11$] = $\{011, 111\}$. Once again $\Theta$ is appended in $\Gamma$ and emptied.

The fourth iteration has $c = 00$, \textit{suffixes}[$c$]$ = \{000, 100\}$ and $mathcal{S}$ as in Figure \ref{fig:trishifttree34}. All the states in \textit{suffixes}[$c$] have the same morph as $c$, so it passes all its tests, keeps its candidacy as True and it is added to $\Theta$.

At the beginning of the next iteration, $\Gamma = \{01, 10, 11\}$, $\Theta = \{00\}$, \textit{suffixes}[$01$] = $\{001, 101\}$, \textit{suffixes}[$10$] = $\{010, 110\}$ and \textit{suffixes}[$11$] = $\{011, 111\}$ and $mathcal{S}$ is still as in Figure \ref{fig:trishifttree34}.After dequeueing, $c = 01$ and \textit{suffixes}[$c$]$ = \{001, 101\}$. The test \textit{statisticalTest}$(01,001)$ fails ([0.779, 0.221] against [0.8, 0.2]). During the expansion, $\Psi = \{010, 011\}$ and $V[01] = \emptyset$. 010 is its own shortest valid suffix, but 011 is not (its shortest valid suffix is 11). This means $V[11] = \{011\}$ and $\Gamma$ appends 010. The children of 010 are 0100 and 0101 and will be added to \textit{suffixes}[00] and \textit{suffixes}[101]. After the expansion, $\Theta = \{00\}$ is appended to $\Gamma$.

In the sixth iteration, $\Gamma = \{10, 11, 010, 00\}$, $V[11] = \{011\}$, \textit{suffixes}[$10$] = $\{010, 110\}$, \textit{suffixes}[$11$] = $\{011, 111\}$,  \textit{suffixes}[$010$] = $\emptyset$ and  \textit{suffixes}[$00$] = $\{000, 100, 0100\}$ and $mathcal{S}$ as in Figure \ref{fig:trishifttree5}. $c = 10$, \textit{suffixes}[$c$]$ = \{010, 110\}$ and \textit{statisticalTest}$(10,010)$ fails ([0.6403, 0.3597] against [0.662, 0.338]). The expansion has $\Psi = \{100, 101\}$. 100 has 00 as shortest valid suffix, therefore it is not appended to $\Gamma$ and $V[00] = \{100\}$. 101 is its own shortest valid suffix so it is queued into $\Gamma$ and its children are 1010 and 1011 which are added to \textit{suffixes}[010] and \textit{suffixes}[11].

The following iteration has $\Gamma = \{11, 010, 00, 101\}$, $V[11] = \{011\}$, $V[00] = \{100\}$, \textit{suffixes}[$11$] = $\{011, 111, 1011\}$,  \textit{suffixes}[$010$] = $\{1010\}$, \textit{suffixes}[$00$] = $\{000, 100, 0100\}$ and \textit{suffixes}[$101$] = $\{0101\}$ and $mathcal{S}$ as in Figure \ref{fig:trishifttree6}. $c = 11$ and \textit{suffixes}[$c$]$ = \{011, 111, 1011\}$. The test \textit{statisticalTest}$(11,011)$ fails ([0.6256, 0.3744] against [0.5575, 0.4425]). In the expansion for $c = 11$, $\Psi = \{110, 111, 011\}$ (because $V[11] = \{011\}$).  All of them are their own shortest valid suffixes, so they are appended to $\Gamma$ and suffixes is updated with \textit{suffixes}[00] receiving 1100; \textit{suffixes}[101] receives 1101; \textit{suffixes}[110], 1110 and 0110; \textit{suffixes}[111], 1111 and 0111.

In the eighth iteration, $\Gamma = \{010, 00, 101, 110, 111, 011\}$, $V[00] = \{100\}$, \textit{suffixes}[$010$] = $\{1010\}$, \textit{suffixes}[$00$] = $\{000, 100, 0100, 1100\}$, \textit{suffixes}[$101$] = $\{0101, 1101\}$, \textit{suffixes}[$110$] = $\{1110, 0110\}$, \textit{suffixes}[$111$] = $\{1111, 0111\}$ and \textit{suffixes}[$011$] = $\{1011\}$ and $mathcal{S}$ as in Figure \ref{fig:trishifttree7}. $c = 010$ which is now equal in length to $W = 3$, which means it is no longer tested.

In the ninth iteration, $c = 00$ and \textit{suffixes}$[c] = \{000, 100, 0100, 1100\}$. All of these states have morphs close to [0.5, 0.5] and they pass in all statistical test. This keeps 00 candidacy as True and it is once again added to $\Theta$. The rest of the elements in $\Gamma = \{101, 110, 111, 011\}$ have labels equal to than $W$ so they are all skipped and the algorithm returns $\Theta = \{00\}$. This result is the same as the one found by CRISSiS. %Although this Algorithm seems more contrived, less statistical tests were performed and the search was more thorough than CRISSiS.

\begin{figure}[H]
\centering
\tikzstyle{level 1}=[level distance=2.5cm, sibling distance=11.5cm]
\tikzstyle{level 2}=[level distance=2.5cm, sibling distance=5.5cm]
\tikzstyle{level 3}=[level distance=3.5cm, sibling distance=3cm]
\tikzstyle{level 4}=[level distance=4.5cm, sibling distance=1.25cm]
\begin{tikzpicture}
	[
    grow = right,
    edge from parent/.style = {draw, -latex},
    every node/.style       = {font=\footnotesize},
    sloped    
    ]
  \node [env] {$\epsilon$}
    child { node [leaf] {1}
      child{ node [leaf] {11}
      	child{ node [leaf] {111}
      		child{ node [leaf] {1111}
      			edge from parent node [below] {1/0.2606}}
      		child{ node [leaf] {1110}
      			edge from parent node [above] {0/0.7394}}
        	edge from parent node [below] {1/0.3744}}
      	child{ node [leaf] {110}
      		child{ node [leaf] {1101}
      			edge from parent node [below] {1/0.4364}}
      		child{ node [leaf] {1100}
      			edge from parent node [above] {0/0.5636}}
        	edge from parent node [above] {0/0.6256}}
      	edge from parent node [below] {1/0.2610}}
      child{ node [leaf] {10}
      	child{ node [leaf] {101}
      		child{ node [leaf] {1011}
      			edge from parent node [below] {1/0.7417}}
      		child{ node [leaf] {1010}
      			edge from parent node [above] {0/0.2583}}
        	edge from parent node [below] {1/0.3597}}
      	child{ node [leaf] {100}
      		child{ node [leaf] {1001}
      			edge from parent node [below] {1/0.5000}}
      		child{ node [leaf] {1000}
      			edge from parent node [above] {0/0.5000}}
        	edge from parent node [above] {0/0.6403}}
      	edge from parent node [above] {0/0.7390}}
      edge from parent node [below] {1/0.3724} }
    child { node [leaf] {0}
      child{ node [leaf] {01}
       	child{ node [leaf] {011}
      		child{ node [leaf] {0111}
      			edge from parent node [below] {1/0.4425}}
      		child{ node [leaf] {0110}
      			edge from parent node [above] {0/0.5575}}
         	edge from parent node [below] {1/0.2210}}
       	child{ node [leaf] {010}
      		child{ node [leaf] {0101}
      			edge from parent node [below] {1/0.3380}}
      		child{ node [leaf] {0100}
      			edge from parent node [above] {0/0.6620}}
         	edge from parent node [above] {0/0.7790}}
      	edge from parent node [below] {1/0.4385}}
      child{ node [leaf] {00}
       	child{ node [leaf] {001}
      		child{ node [leaf] {0011}
      			edge from parent node [below] {1/0.2000}}
      		child{ node [leaf] {0010}
      			edge from parent node [above] {0/0.8000}}
         	edge from parent node [below] {1/0.5000}}
       	child{ node [leaf] {000}
      		child{ node [leaf] {0001}
      			edge from parent node [below] {1/0.5000}}
      		child{ node [leaf] {0000}
      			edge from parent node [above] {0/0.5000}}
         	edge from parent node [above] {0/0.5000}}
      	edge from parent node [above] {0/0.5615}}
      edge from parent node [above] {0/0.6276} };
\end{tikzpicture}
\caption{Rooted Tree with Probabilities $\mathcal{S}$ for the Tri-Shift Example after the first iteration. \label{fig:trishifttree1}}
\end{figure}

\begin{figure}[H]
\centering
\tikzstyle{level 1}=[level distance=2.5cm, sibling distance=11.5cm]
\tikzstyle{level 2}=[level distance=2.5cm, sibling distance=5.5cm]
\tikzstyle{level 3}=[level distance=3.5cm, sibling distance=3cm]
\tikzstyle{level 4}=[level distance=4.5cm, sibling distance=1.25cm]
\begin{tikzpicture}
	[
    grow = right,
    edge from parent/.style = {draw, -latex},
    every node/.style       = {font=\footnotesize},
    sloped    
    ]
  \node [env] {$\epsilon$}
    child { node [leaf] {1}
      child{ node [leaf] {11}
      	child{ node [leaf] {111}
      		child{ node [leaf] {1111}
      			edge from parent node [below] {1/0.2606}}
      		child{ node [leaf] {1110}
      			edge from parent node [above] {0/0.7394}}
        	edge from parent node [below] {1/0.3744}}
      	child{ node [leaf] {110}
      		child{ node [leaf] {1101}
      			edge from parent node [below] {1/0.4364}}
      		child{ node [leaf] {1100}
      			edge from parent node [above] {0/0.5636}}
        	edge from parent node [above] {0/0.6256}}
      	edge from parent node [below] {1/0.2610}}
      child{ node [leaf] {10}
      	child{ node [leaf] {101}
      		child{ node [leaf] {1011}
      			edge from parent node [below] {1/0.7417}}
      		child{ node [leaf] {1010}
      			edge from parent node [above] {0/0.2583}}
        	edge from parent node [below] {1/0.3597}}
      	child{ node [leaf] {100}
      		child{ node [leaf] {1001}
      			edge from parent node [below] {1/0.5000}}
      		child{ node [leaf] {1000}
      			edge from parent node [above] {0/0.5000}}
        	edge from parent node [above] {0/0.6403}}
      	edge from parent node [above] {0/0.7390}}
      edge from parent node [below] {1/0.3724} }
    child { node [env] {0}
      child{ node [leaf] {01}
       	child{ node [leaf] {011}
      		child{ node [leaf] {0111}
      			edge from parent node [below] {1/0.4425}}
      		child{ node [leaf] {0110}
      			edge from parent node [above] {0/0.5575}}
         	edge from parent node [below] {1/0.2210}}
       	child{ node [leaf] {010}
      		child{ node [leaf] {0101}
      			edge from parent node [below] {1/0.3380}}
      		child{ node [leaf] {0100}
      			edge from parent node [above] {0/0.6620}}
         	edge from parent node [above] {0/0.7790}}
      	edge from parent node [below] {1/0.4385}}
      child{ node [leaf] {00}
       	child{ node [leaf] {001}
      		child{ node [leaf] {0011}
      			edge from parent node [below] {1/0.2000}}
      		child{ node [leaf] {0010}
      			edge from parent node [above] {0/0.8000}}
         	edge from parent node [below] {1/0.5000}}
       	child{ node [leaf] {000}
      		child{ node [leaf] {0001}
      			edge from parent node [below] {1/0.5000}}
      		child{ node [leaf] {0000}
      			edge from parent node [above] {0/0.5000}}
         	edge from parent node [above] {0/0.5000}}
      	edge from parent node [above] {0/0.5615}}
      edge from parent node [above] {0/0.6276} };
\end{tikzpicture}
\caption{Rooted Tree with Probabilities $\mathcal{S}$ for the Tri-Shift Example after the second iteration. \label{fig:trishifttree2}}
\end{figure}

\begin{figure}[H]
\centering
\tikzstyle{level 1}=[level distance=2.5cm, sibling distance=11.5cm]
\tikzstyle{level 2}=[level distance=2.5cm, sibling distance=5.5cm]
\tikzstyle{level 3}=[level distance=3.5cm, sibling distance=3cm]
\tikzstyle{level 4}=[level distance=4.5cm, sibling distance=1.25cm]
\begin{tikzpicture}
	[
    grow = right,
    edge from parent/.style = {draw, -latex},
    every state/.style       = {font=\footnotesize},
    sloped    
    ]
  \node [env] {$\epsilon$}
    child { node [env] {1}
      child{ node [leaf] {11}
      	child{ node [leaf] {111}
      		child{ node [leaf] {1111}
      			edge from parent node [below] {1/0.2606}}
      		child{ node [leaf] {1110}
      			edge from parent node [above] {0/0.7394}}
        	edge from parent node [below] {1/0.3744}}
      	child{ node [leaf] {110}
      		child{ node [leaf] {1101}
      			edge from parent node [below] {1/0.4364}}
      		child{ node [leaf] {1100}
      			edge from parent node [above] {0/0.5636}}
        	edge from parent node [above] {0/0.6256}}
      	edge from parent node [below] {1/0.2610}}
      child{ node [leaf] {10}
      	child{ node [leaf] {101}
      		child{ node [leaf] {1011}
      			edge from parent node [below] {1/0.7417}}
      		child{ node [leaf] {1010}
      			edge from parent node [above] {0/0.2583}}
        	edge from parent node [below] {1/0.3597}}
      	child{ node [leaf] {100}
      		child{ node [leaf] {1001}
      			edge from parent node [below] {1/0.5000}}
      		child{ node [leaf] {1000}
      			edge from parent node [above] {0/0.5000}}
        	edge from parent node [above] {0/0.6403}}
      	edge from parent node [above] {0/0.7390}}
      edge from parent node [below] {1/0.3724} }
    child { node [env] {0}
      child{ node [leaf] {01}
       	child{ node [leaf] {011}
      		child{ node [leaf] {0111}
      			edge from parent node [below] {1/0.4425}}
      		child{ node [leaf] {0110}
      			edge from parent node [above] {0/0.5575}}
         	edge from parent node [below] {1/0.2210}}
       	child{ node [leaf] {010}
      		child{ node [leaf] {0101}
      			edge from parent node [below] {1/0.3380}}
      		child{ node [leaf] {0100}
      			edge from parent node [above] {0/0.6620}}
         	edge from parent node [above] {0/0.7790}}
      	edge from parent node [below] {1/0.4385}}
      child{ node [leaf] {00}
       	child{ node [leaf] {001}
      		child{ node [leaf] {0011}
      			edge from parent node [below] {1/0.2000}}
      		child{ node [leaf] {0010}
      			edge from parent node [above] {0/0.8000}}
         	edge from parent node [below] {1/0.5000}}
       	child{ node [leaf] {000}
      		child{ node [leaf] {0001}
      			edge from parent node [below] {1/0.5000}}
      		child{ node [leaf] {0000}
      			edge from parent node [above] {0/0.5000}}
         	edge from parent node [above] {0/0.5000}}
      	edge from parent node [above] {0/0.5615}}
      edge from parent node [above] {0/0.6276} };
\end{tikzpicture}
\caption{Rooted Tree with Probabilities $\mathcal{S}$ for the Tri-Shift Example after the third and fourth iterations. \label{fig:trishifttree34}}
\end{figure}

\begin{figure}[H]
\centering
\tikzstyle{level 1}=[level distance=2.5cm, sibling distance=11.5cm]
\tikzstyle{level 2}=[level distance=2.5cm, sibling distance=5.5cm]
\tikzstyle{level 3}=[level distance=3.5cm, sibling distance=3cm]
\tikzstyle{level 4}=[level distance=4.5cm, sibling distance=1.25cm]
\begin{tikzpicture}
	[
    grow = right,
    edge from parent/.style = {draw, -latex},
    every state/.style       = {font=\footnotesize},
    sloped    
    ]
  \node [env] {$\epsilon$}
    child { node [env] {1}
      child{ node [leaf] {11}
      	child{ node [leaf] {111}
      		child{ node [leaf] {1111}
      			edge from parent node [below] {1/0.2606}}
      		child{ node [leaf] {1110}
      			edge from parent node [above] {0/0.7394}}
        	edge from parent node [below] {1/0.3744}}
      	child{ node [leaf] {110}
      		child{ node [leaf] {1101}
      			edge from parent node [below] {1/0.4364}}
      		child{ node [leaf] {1100}
      			edge from parent node [above] {0/0.5636}}
        	edge from parent node [above] {0/0.6256}}
      	edge from parent node [below] {1/0.2610}}
      child{ node [leaf] {10}
      	child{ node [leaf] {101}
      		child{ node [leaf] {1011}
      			edge from parent node [below] {1/0.7417}}
      		child{ node [leaf] {1010}
      			edge from parent node [above] {0/0.2583}}
        	edge from parent node [below] {1/0.3597}}
      	child{ node [leaf] {100}
      		child{ node [leaf] {1001}
      			edge from parent node [below] {1/0.5000}}
      		child{ node [leaf] {1000}
      			edge from parent node [above] {0/0.5000}}
        	edge from parent node [above] {0/0.6403}}
      	edge from parent node [above] {0/0.7390}}
      edge from parent node [below] {1/0.3724} }
    child { node [env] {0}
      child{ node [env] {01}
       	child{ node [leaf] {011}
      		child{ node [leaf] {0111}
      			edge from parent node [below] {1/0.4425}}
      		child{ node [leaf] {0110}
      			edge from parent node [above] {0/0.5575}}
         	edge from parent node [below] {1/0.2210}}
       	child{ node [leaf] {010}
      		child{ node [leaf] {0101}
      			edge from parent node [below] {1/0.3380}}
      		child{ node [leaf] {0100}
      			edge from parent node [above] {0/0.6620}}
         	edge from parent node [above] {0/0.7790}}
      	edge from parent node [below] {1/0.4385}}
      child{ node [leaf] {00}
       	child{ node [leaf] {001}
      		child{ node [leaf] {0011}
      			edge from parent node [below] {1/0.2000}}
      		child{ node [leaf] {0010}
      			edge from parent node [above] {0/0.8000}}
         	edge from parent node [below] {1/0.5000}}
       	child{ node [leaf] {000}
      		child{ node [leaf] {0001}
      			edge from parent node [below] {1/0.5000}}
      		child{ node [leaf] {0000}
      			edge from parent node [above] {0/0.5000}}
         	edge from parent node [above] {0/0.5000}}
      	edge from parent node [above] {0/0.5615}}
      edge from parent node [above] {0/0.6276} };
\end{tikzpicture}
\caption{Rooted Tree with Probabilities $\mathcal{S}$ for the Tri-Shift Example after the fifth iteration. \label{fig:trishifttree5}}
\end{figure}

\begin{figure}[H]
\centering
\tikzstyle{level 1}=[level distance=2.5cm, sibling distance=11.5cm]
\tikzstyle{level 2}=[level distance=2.5cm, sibling distance=5.5cm]
\tikzstyle{level 3}=[level distance=3.5cm, sibling distance=3cm]
\tikzstyle{level 4}=[level distance=4.5cm, sibling distance=1.25cm]
\begin{tikzpicture}
	[
    grow = right,
    edge from parent/.style = {draw, -latex},
    every state/.style       = {font=\footnotesize},
    sloped    
    ]
  \node [env] {$\epsilon$}
    child { node [env] {1}
      child{ node [leaf] {11}
      	child{ node [leaf] {111}
      		child{ node [leaf] {1111}
      			edge from parent node [below] {1/0.2606}}
      		child{ node [leaf] {1110}
      			edge from parent node [above] {0/0.7394}}
        	edge from parent node [below] {1/0.3744}}
      	child{ node [leaf] {110}
      		child{ node [leaf] {1101}
      			edge from parent node [below] {1/0.4364}}
      		child{ node [leaf] {1100}
      			edge from parent node [above] {0/0.5636}}
        	edge from parent node [above] {0/0.6256}}
      	edge from parent node [below] {1/0.2610}}
      child{ node [env] {10}
      	child{ node [leaf] {101}
      		child{ node [leaf] {1011}
      			edge from parent node [below] {1/0.7417}}
      		child{ node [leaf] {1010}
      			edge from parent node [above] {0/0.2583}}
        	edge from parent node [below] {1/0.3597}}
      	child{ node [leaf] {100}
      		child{ node [leaf] {1001}
      			edge from parent node [below] {1/0.5000}}
      		child{ node [leaf] {1000}
      			edge from parent node [above] {0/0.5000}}
        	edge from parent node [above] {0/0.6403}}
      	edge from parent node [above] {0/0.7390}}
      edge from parent node [below] {1/0.3724} }
    child { node [env] {0}
      child{ node [env] {01}
       	child{ node [leaf] {011}
      		child{ node [leaf] {0111}
      			edge from parent node [below] {1/0.4425}}
      		child{ node [leaf] {0110}
      			edge from parent node [above] {0/0.5575}}
         	edge from parent node [below] {1/0.2210}}
       	child{ node [leaf] {010}
      		child{ node [leaf] {0101}
      			edge from parent node [below] {1/0.3380}}
      		child{ node [leaf] {0100}
      			edge from parent node [above] {0/0.6620}}
         	edge from parent node [above] {0/0.7790}}
      	edge from parent node [below] {1/0.4385}}
      child{ node [leaf] {00}
       	child{ node [leaf] {001}
      		child{ node [leaf] {0011}
      			edge from parent node [below] {1/0.2000}}
      		child{ node [leaf] {0010}
      			edge from parent node [above] {0/0.8000}}
         	edge from parent node [below] {1/0.5000}}
       	child{ node [leaf] {000}
      		child{ node [leaf] {0001}
      			edge from parent node [below] {1/0.5000}}
      		child{ node [leaf] {0000}
      			edge from parent node [above] {0/0.5000}}
         	edge from parent node [above] {0/0.5000}}
      	edge from parent node [above] {0/0.5615}}
      edge from parent node [above] {0/0.6276} };
\end{tikzpicture}
\caption{Rooted Tree with Probabilities $\mathcal{S}$ for the Tri-Shift Example after the sixth iteration. \label{fig:trishifttree6}}
\end{figure}

\begin{figure}[H]
\centering
\tikzstyle{level 1}=[level distance=2.5cm, sibling distance=11.5cm]
\tikzstyle{level 2}=[level distance=2.5cm, sibling distance=5.5cm]
\tikzstyle{level 3}=[level distance=3.5cm, sibling distance=3cm]
\tikzstyle{level 4}=[level distance=4.5cm, sibling distance=1.25cm]
\begin{tikzpicture}
	[
    grow = right,
    edge from parent/.style = {draw, -latex},
    every state/.style       = {font=\footnotesize},
    sloped    
    ]
  \node [env] {$\epsilon$}
    child { node [env] {1}
      child{ node [env] {11}
      	child{ node [leaf] {111}
      		child{ node [leaf] {1111}
      			edge from parent node [below] {1/0.2606}}
      		child{ node [leaf] {1110}
      			edge from parent node [above] {0/0.7394}}
        	edge from parent node [below] {1/0.3744}}
      	child{ node [leaf] {110}
      		child{ node [leaf] {1101}
      			edge from parent node [below] {1/0.4364}}
      		child{ node [leaf] {1100}
      			edge from parent node [above] {0/0.5636}}
        	edge from parent node [above] {0/0.6256}}
      	edge from parent node [below] {1/0.2610}}
      child{ node [env] {10}
      	child{ node [leaf] {101}
      		child{ node [leaf] {1011}
      			edge from parent node [below] {1/0.7417}}
      		child{ node [leaf] {1010}
      			edge from parent node [above] {0/0.2583}}
        	edge from parent node [below] {1/0.3597}}
      	child{ node [leaf] {100}
      		child{ node [leaf] {1001}
      			edge from parent node [below] {1/0.5000}}
      		child{ node [leaf] {1000}
      			edge from parent node [above] {0/0.5000}}
        	edge from parent node [above] {0/0.6403}}
      	edge from parent node [above] {0/0.7390}}
      edge from parent node [below] {1/0.3724} }
    child { node [env] {0}
      child{ node [env] {01}
       	child{ node [leaf] {011}
      		child{ node [leaf] {0111}
      			edge from parent node [below] {1/0.4425}}
      		child{ node [leaf] {0110}
      			edge from parent node [above] {0/0.5575}}
         	edge from parent node [below] {1/0.2210}}
       	child{ node [leaf] {010}
      		child{ node [leaf] {0101}
      			edge from parent node [below] {1/0.3380}}
      		child{ node [leaf] {0100}
      			edge from parent node [above] {0/0.6620}}
         	edge from parent node [above] {0/0.7790}}
      	edge from parent node [below] {1/0.4385}}
      child{ node [leaf] {00}
       	child{ node [leaf] {001}
      		child{ node [leaf] {0011}
      			edge from parent node [below] {1/0.2000}}
      		child{ node [leaf] {0010}
      			edge from parent node [above] {0/0.8000}}
         	edge from parent node [below] {1/0.5000}}
       	child{ node [leaf] {000}
      		child{ node [leaf] {0001}
      			edge from parent node [below] {1/0.5000}}
      		child{ node [leaf] {0000}
      			edge from parent node [above] {0/0.5000}}
         	edge from parent node [above] {0/0.5000}}
      	edge from parent node [above] {0/0.5615}}
      edge from parent node [above] {0/0.6276} };
\end{tikzpicture}
\caption{Rooted Tree with Probabilities $\mathcal{S}$ for the Tri-Shift Example after the seventh iteration. \label{fig:trishifttree7}}
\end{figure}

\newpage

\section{PFSA Construction \label{sec:pfsacons}}

In this section, we discuss the ALEPH algorithm that constructs a PFSA from the RTP $\mathcal{S}$. Whether synchronization words are found or not will influence the operations of the algorithm. The first step is to transform $\mathcal{S}$ into a graph as no leaf states (i.e. states with no outgoing edges) can exist during the PFSA construction. This transformation is done via the criteria described in Section \ref{sec:treeterm}.

 The final procedure will groups states in equivalence classes of states that have statistically similar morphs (checked by $\chi^2$ or Kolmogorov-Smirnov for a given confidence level $\alpha$ using the same \textit{statisticalTest} auxiliary function described in Section \ref{sec:findsynch}) and the partition given by these equivalence classes is used as an initial partition for a graph minimization algorithm (such as Moore or Hopcroft) to obtain the final reduced PFSA. This is the main contribution of the ALEPH algorithm. It manages to first get a reduced set of equivalence classes, with states in each class sharing statistically similar morphs, and then breaks them apart to obtain a final set of states that generate sequences similar to the original while having as little redundant states as possible for the given input parameters.

\subsection{RTP Leaf Connection Criteria\label{sec:treeterm}}

%Unlike CRISSiS, the algorithms developed in this work need the rooted tree with probabilities to end, otherwise it will keep going without end. The rooted tree with probabilities raised from the sub-sequence probabilities will end in the $L$th level whose states will have outgoing edges initially pointing out to nowhere. 
The ALEPH algorithm creates equivalence classes for states with statistically similar morphs. In order to have every state in an equivalence class, all of them need to have a morph, which is not the case for leaf states. Two criteria are used to connect the leaf states of the RTP $\mathcal{S}$ and turn it into a PFSA: the first one, the D-Markov connection, is more straightforward while the $\Omega$ connection depends on the system having synchronization words and is able to create connections that better represent the original system.

\subsubsection{D-Markov Connection}

This is the simplest connection criterion. It will aim to form a D-Markov Machine with the states in the last level. This means that a state labeled with $\omega = \sigma_0\sigma_1\ldots\sigma_L \in \Sigma^L$ hass its $\tau \in \Sigma$ labeled edge connected to the state labeled with $\sigma_1\sigma_2\ldots\sigma_L\tau$ for each $\tau \in \Sigma$. This is shown in Algorithm \ref{alg:dmarkterm}. This connection counts on the amount of cases that are captured in a D-Markov machine and applying the subsequent steps in ALEPH to reduce the PFSA size. 

  \begin{algorithm}
  \caption{dmarkovTermination($\mathcal{S}, L$)\label{alg:dmarkterm}}
    \begin{algorithmic}[1]
      \Procedure{Connect}{}
      	\State $\Psi \gets \{q \in \mathcal{S}$ if $q$ in level $L\}$
      	\For{$p \in \Psi$}
      		\State For $p = \sigma_0\sigma_1\ldots\sigma_L$
      		\For{$\tau \in \Sigma$}
      			\State $\delta(\tau, p) \gets \sigma_1\sigma_2\ldots\sigma_L\tau$
      		\EndFor
      	\EndFor
      \EndProcedure
    \end{algorithmic}
  \end{algorithm}
  
%\textbf{TO DO:}Figure \ref{fig:trishiftdmark} shows the rooted tree with probabilities from the Trishift example with $L=3$ and the D-Markov termination.
%
%%\begin{figure}
%%\centering
%%\begin {tikzpicture}[-latex ,auto ,node distance =2 cm and 2 cm ,on grid ,
%%semithick ,
%%state/.style ={ circle , draw = black , text=black , minimum width =1 cm}]
%%\node[state] (root)
%%{$\epsilon$};
%%\node[state] (0) [above right=of root] {$0$};
%%\node[state] (1) [below right =of root] {$1$};
%%\node[state] (00) [above right =of 0] {$00$};
%%\node[state] (01) [right =of 0] {$01$};
%%\node[state] (10) [right =of 1] {$10$};
%%\node[state] (11) [below right =of 1] {$11$};
%%\node[state] (000) [above =of 00] {$000$};
%%\node[state] (001) [above right =of 00] {$001$};
%%\node[state] (010) [above right =of 01] {$010$};
%%\node[state] (011) [right =of 01] {$011$};
%%\node[state] (100) [right =of 10] {$100$};
%%\node[state] (101) [below right =of 10] {$101$};
%%\node[state] (110) [below right =of 11] {$110$};
%%\node[state] (111) [below =of 11] {$111$};
%%\path (root) edge state[above] {$0$} (0);
%%\path (root) edge state[below] {$1$} (1);
%%\path (0) edge state[above] {$1$} (00);
%%\path (0) edge state[below] {$0$} (01);
%%\path (1) edge state[above] {$0$} (10);
%%\path (1) edge state[below] {$1$} (11);
%%\path (00) edge state[left] {$0$} (000);
%%\path (00) edge state[below] {$1$} (001);
%%\path (01) edge state[above] {$0$} (010);
%%\path (01) edge state[below] {$1$} (011);
%%\path (10) edge state[above] {$0$} (100);
%%\path (10) edge state[below] {$1$} (101);
%%\path (11) edge state[above] {$0$} (110);
%%\path (11) edge state[left] {$1$} (111);
%%\path (000) [loop left] edge state[left] {$0$} (000);
%%\path (000) edge state[above] {$1$} (001);
%%\path (001) edge state[right] {$0$} (010);
%%\path (001) [bend left] edge state[right] {$1$} (011);
%%\path (010) [bend left] edge state[right] {$0$} (100);
%%\path (010) [bend right=1.0cm] edge state[below =0.15 cm] {$1$} (101);
%%\path (011) [bend left] edge state[below =0.15 cm] {$0$} (110);
%%\path (011) [bend left] edge state[below =0.15 cm] {$1$} (111);
%%\path (100) [bend left] edge state[below =0.15 cm] {$0$} (000);
%%\path (100) [bend left] edge state[below =0.15 cm] {$1$} (001);
%%\path (101) [bend left] edge state[below =0.15 cm] {$0$} (010);
%%\path (101) [bend left] edge state[below =0.15 cm] {$1$} (011);
%%\path (110) [bend right] edge state[right] {$0$} (100);
%%\path (110) edge state[right] {$1$} (101);
%%\path (111) [loop left] edge state[left] {$1$} (111);
%%\path (111) edge state[below] {$0$} (110);
%%\end{tikzpicture}
%%\caption{Tri-Shift rooted tree with probabilities with D-Markov termination and $L=3$.\label{fig:trishiftdmark}}
%%\end{figure}
%
\subsubsection{$\Omega$ Connection}

%This connection criterion relies more on using synchronization words, which means it is more suitable to systems that synchronize and that have some memory. 

For each state $p$ in level $L+1$ of $\mathcal{S}$, this criterion checks via statistical test if $p$ has similar morph to any of the synchronization words states. If it is not, it subsequently tests with the morphs of each extension of synchronization words up to length $L$. If any of these tests succeeds, the state $q$ in level $L$ that has $\delta(\tau,q) = p$ for $\tau \in \Sigma$ has this edge reassigned for the state with which the test was successful. In case no test passes, the D-Markov criteria is used for $q$. This is shown in Algorithm \ref{alg:omegaterm} whose inputs are the RTP $\mathcal{S}$, the desired last level $L$ and a list of synchronization words $\Omega_{syn}$.  

  \begin{algorithm}
  \caption{omegaConnection($\mathcal{S}, L, \Omega_{syn}$)\label{alg:omegaterm}}
    \begin{algorithmic}[1]
      \Procedure{Connect}{}
      	\State $\Psi \gets \{p \in \mathcal{S}$ if $p$ in level $L\}$
      	\For{$q \in \Psi$}
      		\State next = NULL
      		\For{$\tau \in \Sigma$}
      			\State $q^{\prime} = \delta(\tau,q)$
      			\For{$\omega \in \Omega_{syn}$}
      				\State $r \gets$ \textit{statisticalTest}($q^{\prime},\omega, \alpha$)
      				\If{$r = True$}
      					\State next $\gets \omega$
      					\State \textbf{break}
      				\EndIf
      			\EndFor
      			\If{next = NULL}
      				\State $\eta \gets \{$All extensions of $\omega$ up to length $L, \forall \omega \in \Omega_{syn}\}$
      				\For{$e \in \eta$}
      				\State $r \gets$ \textit{statisticalTest}($q^{\prime}, e, \alpha$)
      					\If{$r = True$}
      						\State next $\gets e$
      						\State \textbf{break}
      					\EndIf
      				\EndFor
      			\EndIf
      			\If{next = NULL}
      				\State Given that $q = \sigma_0\ldots\sigma_L$
      			\EndIf
      			\State $\delta(\tau,m) \gets \sigma_1\ldots\sigma_L\tau$
      		\EndFor
      	\EndFor
      \EndProcedure
    \end{algorithmic}
  \end{algorithm}

\subsection{ALEPH Algorithm}

The full ALEPH algorithm is shown in Algorithm \ref{alg:aleph}. It takes an RTP $\mathcal{S}$, the maximum considered depth $L$ and a list of synchronization words $\Omega_{syn}$ as inputs. It is further broken in 3 steps: the RTP leaf termination, separating the states in an initial partition of equivalence classes and applying a graph minimization algorithm.

\subsubsection{Step 1: RTP Leaf Termination}

There are two cases for leaf termination: when $\Omega_{syn}$ is empty (no synchronization words) and when it is not.

When  $\Omega_{syn}$ list is not empty, the $\Omega$ connection is used in $\mathcal{S}$. After the connection process is finished a process is used to discard some branches of $\mathcal{S}$ in order to obtain fewer starting states in the next two steps, which implies in a smaller complexity. Each state $q^{\prime}\in\mathcal{S}$ is visited, starting by the synchronization word states and it is checked if any of its descendents (i.e. $\delta(q^{\prime},\sigma)$ for some $\sigma \in \Sigma$) has a synchronization word $\omega$ as suffix. In the affirmative case, this outgoing edge is reassigned to $\omega$. This is done because a state that has a synchronization word as suffix has a morph similar to the synchronization word and generate the same sequences with the same probabilities, which means these longer states that have synchronization words as suffixes can be discarded. By discarding them, the rest of its branch is also discarded, reducing the number of initial states even further. 

This is done by creating a copy of $\Omega_{syn}$ called $Q_0$ and an empty list called $P_1$. The first element in the list is taken by a dequeue and stored in $q_0$, which means starting to visit the state of $\mathcal{S}$ by the synchronization words. All descendants of $q_0$ are checked to see if they have one of the synchronization words as suffix, and in the affirmative case $\delta(q_0,\sigma)$ is reassigned to that synchronization word (lines 9 to 12 of Algorithm \ref{alg:aleph}). If a descendant of $q_0$ does not end in a synchronization word, the descendant is added to the list $Q_0$ if it not already in it and neither in $P_0$ (lines 13 to 15 of Algorithm \ref{alg:aleph}). This is done to make sure states will not be visited twice. After all descendants of $q_0$ are checked, $q_0$ is appended to $P_0$.

Finally, the initial equivalence classes are created: one for each synchronization word (line 17 of Algorithm \ref{alg:aleph}).

Otherwise, the D-Markov connection is applied to $\mathcal{S}$ and a starting equivalence class is created with just the root state $\epsilon$ (lines 18 to 20 of Algorithm \ref{alg:aleph}). 

\subsubsection{Step 2: Grouping in Equivalence Classes}

The initial equivalence classes created in the previous step are stored in the list $\mathcal{P}$. Given an equivalence class $p$, its head state is the first state that is added to $p$ and it is denoted by $p[0]$. A list $Q$ is created containing the descendants of the head states in each of the initial equivalence classes.  

For each element $q$ of $Q$, statistical tests are performed with the head state of each partition $p$ already present in $\mathcal{P}$. If a test result is positive, the state $q$ is added to the partition $p$. If no test is successful, a new equivalence class is created for $q$ and this class is subsequently added to $\mathcal{P}$. This process is repeated until every state of $\mathcal{S}$ is present in one equivalence class of the partition $\mathcal{P}$.

\subsection{Step 3: Graph Minimization}

  Once every state of $\mathcal{S}$ is in one class of the initial partition $\mathcal{P}$, a graph minimization algorithm (either Moore or Hopcroft) is applied using $\mathcal{P}$ as the initial partition. This initial partition guarantees that the elements in the equivalence class have the same morph and the reduction algorithm will break this class if they eventually point to states with different morphs.  The final result is the PFSA that represents the original system for the given parameters.  

%Two different methods can be used to retrieve the final PFSA: the $\aleph_0$ and $\aleph_1$ algorithms. As with the termination criteria, each one of them is better suited for a specific type of application. The $\aleph_0$ algorithm is less dependent on synchronization words and performs better in systems that do not synchronize. The $\aleph_1$ algorithm is faster, but heavily relies on synchronization words, so it tends to construct better PFSA when the original system synchronizes. Both algorithms take as inputs a terminated rooted tree with probabilities (using one of the criteria from Section \ref{sec:treeterm}) $\mathcal{S}$ and a list of synchronization words $\Omega_{syn}$.
%
%\subsection{$\aleph_0$ Algorithm}
%
%This algorithm starts by taking only the first element of $\Omega_{syn}$ as $\omega$. If the system has no synchronization words, $\omega$ is then the root state $\epsilon$. The algorithm will then expand the children states of $\omega$ and compare them with $\omega$ via statistical test. If the test passes, the states are grouped together in the same partition. If not, a new partition is created for that state. This procedure is then repeated for each subsequent state until all states of $\mathcal{S}$ are in one partition. These partitions are then used as an initial partition for the Moore or Hopcroft Algorithms. This is shown in Algorithm \ref{alg:aleph0}.
%
%By applying this algorithm, states that have similar morphs are grouped together as they potentially produce the same sequences. By applying a graph reduction algorithm after the initial partition, states with similar morphs but distinct languages are then separated, while the ones with same languages are kept together. This procedure reduces the number of redundant states (the ones with same morphs and same languages).
%
%\begin{algorithm}
%  \caption{$\aleph_0$($\mathcal{S}, \Omega_{syn}$)\label{alg:aleph0}}
%    \begin{algorithmic}[1]
%      \Procedure{}{}
%      	\If{$\Omega_{syn} \neq \emptyset$}
%      		\State $\omega \gets \Omega_{syn}[0]$
%      	\Else
%      		\State $\omega \gets \epsilon$
%      	\EndIf
%      	\State $P \gets \{\omega\}$
%      	\State $\mathcal{P} \gets \{P\}$
%      	\State $Q \gets \{\delta(\sigma,\omega), \forall \sigma \in \Sigma\}$
%      	\For{$q \in Q$}
%      		\State $r \gets$ False
%      		\For{$p \in \mathcal{P}$}
%      			\State $r \gets \mathcal{V}(q) = \mathcal{V}(p[0])$
%      			\If{$r =$ True}
%      				\State $p \gets p\bigcup\{q\}$
%      				\State \textbf{break}
%      			\EndIf
%      		\EndFor
%      		\If{$r =$ False}
%      			\State $R \gets \{q\}$
%      			\State $\mathcal{P} \gets \mathcal{P}\bigcup\{R\}$
%      		\EndIf 
%      		\State $Q \gets Q\bigcup\{\delta(\sigma,q),\forall \sigma\in\Sigma|\delta(\sigma,q)$ not in any $p\in\mathcal{P}\}$
%      	\EndFor
%      	\State $G \gets$ GraphReduction($\mathcal{P}$)
%      	\State \textbf{return} $G$
%      \EndProcedure
%    \end{algorithmic}
%  \end{algorithm}
%
\begin{algorithm}
  \caption{ALEPH($\mathcal{S}, \Omega_{syn}, L$)\label{alg:aleph}}
    \begin{algorithmic}[1]
      \Procedure{}{}
      	\State \textbf{\#\# Step 1: RTP Leaf State Connection}
      	\If{$\Omega_{syn} \neq \emptyset$}
      		\State $\mathcal{S} \gets$ \textit{omegaConnection}($\mathcal{S}, L$)
	      	\State $Q_0 \gets \Omega_{syn}$
	      	\State $P_0 \gets \emptyset$
	      	\While{$Q_0 \neq \emptyset$}
	      		\State $q_0 \gets$ dequeue($Q_0$)
	      		\For{$\sigma \in \Sigma$}
	      			\State $q_0^{\prime} \gets \delta(q_0,\sigma)$
	      			\If{for some $\omega \in \Omega_{syn}, \omega$ is a suffix of $q_0^{\prime}$}
	      				\State $\delta(\sigma,q_0) \gets \omega$
	      			\Else
	      				\If{$q_0^{\prime} \notin Q_0$ and $q_0^{\prime} \notin P_0$}
	      					\State $Q_0 \gets Q_0\cup\{q_0'\}$
	      				\EndIf 
	      			\EndIf
	      			\State $P_0 \gets P_0\cup\{q_0\}$
	      		\EndFor
	      	\EndWhile	      	
      		\State $\mathcal{P} \gets \{\{\omega\}, \forall \omega \in \Omega_{syn}\}$
      	\Else
      		\State $\mathcal{S} \gets$ \textit{dmarkovConnection}($\mathcal{S}, L$)
      		\State $\mathcal{P} \gets \{\epsilon\}$
      	\EndIf
      	\State \textbf{\#\# Step 2: Grouping in Equivalence Classes}
      	\State $Q \gets \{\delta(\sigma, q_1[0]), \, \forall \sigma \in \Sigma$ and $\forall q_1[0]\in \mathcal{P}\}$
      	\For{$q \in Q$}
      		\State $r \gets$ False
      		\For{$p \in \mathcal{P}$}
      			\State $r \gets$ \textit{statisticalTest}($q, p[0], \aleph$)
      			\If{$r =$ True}
      				\State $p \gets p\cup\{q\}$
      				\State \textbf{break}
      			\EndIf
      		\EndFor
      		\If{$r =$ False}
      			\State $R \gets \{q\}$
      			\State $\mathcal{P} \gets \mathcal{P}\cup\{R\}$
      		\EndIf 
      		\State $Q \gets Q\cup\{\delta(\sigma,q),\forall \sigma\in\Sigma|\delta(\sigma,q)$ not in any $p\in\mathcal{P}\}$
      	\EndFor
      	\State \textbf{\#\# Step 3: Graph Minimization (either Moore or Hopcroft)}
      	\State $G \gets$ GraphMin($\mathcal{P}$)
      	\State \textbf{return} $G$
      \EndProcedure
    \end{algorithmic}
  \end{algorithm}
%
%
%\subsection{$\aleph_1$ Algorithm}
%
%The $\aleph_1$ algorithm is similar to $\aleph_0$, but it includes a step prior to creating the initial partition for the graph reduction algorithm in order to make a smaller initial partition, which, in turn, makes the graph reduction faster. This step uses all synchronization words in $\Omega_{syn}$ as starting points and checks if any of them has an edge pointing to a state whose label has a synchronization word as suffix. If it has, this edge is reassigned to point to that synchronization word. This procedure is then repeated for each subsequent state in $\mathcal{S}$. Words ending in synchronization words will always point again to the synchronization word state. This procedure reduces the number of states as anything ending with a synchronization word and its extensions will not be used anymore. As the following steps have their complexities depending on number of states, this will speed up the rest of the process.
%
%Once this is done, the rest of the algorithm will repeat $\aleph_0$: starting from the synchronization words, its children will have their morphs compared and partitions will be created following this criterion. When the initial partition is finished, a graph reduction algorithm is applied. Algorithm $\aleph_1$ is shown in Algorithm \ref{alg:aleph1}.
%
%\begin{algorithm}
%  \caption{$\aleph_1$($\mathcal{S}, \Omega_{syn}$)\label{alg:aleph1}}
%    \begin{algorithmic}[1]
%      \Procedure{}{}
%      	\State $Q_0 \gets \Omega_{syn}$
%      	\State $Q_1 \gets \emptyset$
%      	\While{$Q_0 \neq \emptyset$}
%      		\State $q \gets Q_0.pop()$
%      		\For{$\sigma \in \Sigma$}
%      			\State $q' \gets \delta(q,\sigma)$
%      			\If{for some $\omega \in \Omega_{syn}, \omega$ is a suffix of $q'$}
%      				\State $\delta(\sigma,q) \gets \omega$
%      			\Else
%      				\If{$q' \notin Q_0$ and $q' \notin Q_1$}
%      					\State $Q_0 \gets Q_0\bigcup\{q'\}$
%      				\EndIf 
%      			\EndIf
%      			\State $Q_1 \gets Q_1\bigcup\{q\}$
%      		\EndFor
%      	\EndWhile
%      	\State \textit{$\#\#$ From here on, the algorithm is a slight variation of $\aleph_0\#\#$}
%      	\State $\mathcal{P} \gets \{\{\omega\}, \forall \omega \in \Omega_{syn}\}$
%      	\State $Q \gets \{\delta(\sigma,\omega), \forall \sigma \in \Sigma, \forall \omega \in \Omega_{syn}\}$
%      	\For{$q \in Q$}
%      		\State $r \gets$ False
%      		\For{$p \in \mathcal{P}$}
%      			\State $r \gets \mathcal{V}(q) = \mathcal{V}(p[0])$
%      			\If{$r =$ True}
%      				\State $p \gets p\bigcup\{q\}$
%      				\State \textbf{break}
%      			\EndIf
%      		\EndFor
%      		\If{$r =$ False}
%      			\State $R \gets \{q\}$
%      			\State $\mathcal{P} \gets \mathcal{P}\bigcup\{R\}$
%      		\EndIf 
%      		\State $Q \gets Q\bigcup\{\delta(\sigma,q),\forall \sigma\in\Sigma|\delta(\sigma,q)$ not in any $p\in\mathcal{P}\}$
%      	\EndFor
%      	\State $G \gets$ GraphReduction($\mathcal{P}$)
%      	\State \textbf{return} $G$
%      \EndProcedure
%    \end{algorithmic}
%  \end{algorithm}
%
%
%%\section{Complete Algorithm}
%%
%%The final algorithm consists of the steps presented in the previous sections. The input is the original sequence \textit{S} and the algorithm outputs a PFSA.
%%
%%\begin{enumerate}
%%\item[1] Find synchronization words from sequence \textit{S};
%%\item[2] Apply a termination criterion for the rooted tree with probabilities $mathcal{S}$ based on \textit{S};
%%	\begin{enumerate}
%%	\item Use D-Markov Termination if no synchronization words were found;
%%	\item Use $\Omega$ if synchronization words were found;
%%	\end{enumerate}
%%\item[3] Apply a PFSA construction algorithm ($\aleph_0$ or $\aleph_1$).
%%\end{enumerate}
%
\section{Time Complexity}

The main improvements of the ALEPH algorithm are that, unlike CRISSiS, it does not depend on the original system being synchronizable (the original system does not even need to be represented by a PFSA and ALEPH will generate a PFSA that approximates it) . As seen in \citep{asok.11}, CRISSiS complexity depends on the number of states of the original system which (seen in Section \ref{crissiscomplex}), in practical applications, remains unknown until the end of the algorithm. As it is discussed in this section, the complexity of ALEPH depends only on parameters known prior to the algorithm execution. The complexity of each part of the algorithm is discussed individually and a final complexity is given in the end.

\subsection{RTP Construction}

To construct the RTP, the original sequence $S$ of length $N$ has to be parsed $L$ times, which depends mainly on the sequence length, giving a final complexity $O(N)$.

\subsection{Synchronization Word Search}

For a given state with length $n < W$, the maximum amount of statistical tests it goes through is $n$ for each of its suffixes, starting by $\epsilon$. For each of these tests, one search for SVS is performed. This search for SVS has complexity $O(m)$ for a SVS of length $m$. Thus, for the given state of length $n$, searches for SVS of length 0 to $n-1$ are performed, resulting in a complexity of $O(n^2)$ for the searches. As in CRISSiS, a complexity of $O(1)$ is used for the statistical test. This implies that for a given state of length $n$, $O(n^3)$ operations are performed. This can be simplified if after a search for SVS the result is stored. When a new search for SVS has to be performed, it can start from where the last one finished. This means that for a state of length $n$, the searches have complexity $O(n)$ and the final complexity is $O(n^2)$.

Looking at $\mathcal{S}$, for a given level $d$, $|\Sigma|^d$ tests and searches for SVS of length $d$ are performed, giving a complexity of $O(|\Sigma|^dd^2)$ per level. The total complexity is the sum of all levels from 1 to $W$. Therefore, it is $O(\sum\limits_{d=1}^{W}|\Sigma|^dd^2)$ and as usually $W > |\Sigma|$, the final complexity for the synchronization word search is $O(\frac{|\Sigma|^{W+1}W^2}{|\Sigma|-1})$. 

The complexity for the same operation in CRISSiS is $|\Sigma|^{(|Q|^3 + L_1 + L_2)}$. As it is exponential on the cube of the number of states of the original machine, it grows much faster than our solution.

\subsection{RTP Leaf Connection}

In the D-Markov connection, each of the $|\Sigma|^L$ elements in the last level has their $|\Sigma|$ edges reassigned, giving a complexity of $O(|\Sigma|^{L+1})$.

The $\Omega$ connection is a little more complex to analyze. It also needs to perform operations for each of the $|\Sigma|$ outgoing edges of each of the $|\Sigma|^{L}$ states in level $L$, but those operations are not simply reconnections of complexity $O(1)$. It performs tests with all states in $\Omega_{syn}$ and its descendants up to length $L$, which in a worst case scenario means testing against states from level 0 to $L$ in a total of $O(|\Sigma||\Omega_{syn}|L^2)$ tests per state in the last level and a final complexity of $O(|\Sigma|^{L+1}|\Omega_{syn}|L^2)$.

\subsection{PFSA Construction}

When there are synchronization words, the algorithm starts by checking if all the $|\Sigma|^L$ states have an outgoing edge that could be substituted by a synchronization word, giving a final complexity of $O(|\Sigma|^{L+1})$ for this additional step.

The worst case scenario occurs when all the $|\Sigma|^{L+1}$ states of $\mathcal{S}$ have their own equivalence classes. In this case, the $d^{th}$ has to be tested against the $d-1$ previous equivalence classes, giving a complexity of $O(d)$. The complexity for all states is $O(1 + 2 + \ldots + |\Sigma|^{L+1}) = O(|\Sigma|^{2L+2})$. As seen in \cite{berstel.10}, this is the same procedure that dominates the complexity of graph reduction algorithms, therefore their complexity by the end of the ALEPH algorithm does not need to be considered. 

When there are synchronization words and the first step of complexity $O(|\Sigma|^{L+1})$ is applied, the number of states that will be organized in equivalence classes might be dramatically reduced, which also reduces the complexity of that step. But in the worst case scenario, the $O(|\Sigma|^{2L+2})$ factor dominates the PFSA construction step and is its final complexity.